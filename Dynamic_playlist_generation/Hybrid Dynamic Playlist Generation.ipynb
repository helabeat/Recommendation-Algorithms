{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_listen = pd.read_csv('Copy of explicit_data - Data preprocessing - songs.csv')\n",
    "songs = pd.read_csv('Copy of explicit_data - Songs - All.csv')\n",
    "songs_with_artist_id = pd.read_csv('Copy of explicit_data - Songs - All-with artist_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(user_listen, songs.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>hours_spending</th>\n",
       "      <th>musical_aspect</th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>174</td>\n",
       "      <td>Sandaganawa</td>\n",
       "      <td>Dhanith Sri</td>\n",
       "      <td>Sandaganawa - Dhanith Sri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>220</td>\n",
       "      <td>Api hagum walata ida dee mohothak</td>\n",
       "      <td>Victor Rathnayaka</td>\n",
       "      <td>Api hagum walata ida dee mohothak - Victor Rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>25 - 34</td>\n",
       "      <td>Male</td>\n",
       "      <td>Working</td>\n",
       "      <td>2 - 3</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>221</td>\n",
       "      <td>Mandaram Wahi Watena</td>\n",
       "      <td>6th Lane</td>\n",
       "      <td>Mandaram Wahi Watena - 6th Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10003</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>164</td>\n",
       "      <td>Ru Sara</td>\n",
       "      <td>Bathiya &amp; Santhush</td>\n",
       "      <td>Ru Sara - Bathiya &amp; Santhush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10004</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Male</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>6</td>\n",
       "      <td>Adanne Ay Sudu Manike</td>\n",
       "      <td>H. R. Jothipala</td>\n",
       "      <td>Adanne Ay Sudu Manike - H. R. Jothipala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id age_group  gender         profession hours_spending  \\\n",
       "0    10001   18 - 24  Female            Student          0 - 1   \n",
       "1    10001   18 - 24  Female            Student          0 - 1   \n",
       "2    10002   25 - 34    Male            Working          2 - 3   \n",
       "3    10003   18 - 24  Female  Software Engineer    more than 5   \n",
       "4    10004   18 - 24    Male  software engineer    more than 5   \n",
       "\n",
       "       musical_aspect  song_id                              Title  \\\n",
       "0         Tempo/speed      174                        Sandaganawa   \n",
       "1         Tempo/speed      220  Api hagum walata ida dee mohothak   \n",
       "2  The singer's voice      221               Mandaram Wahi Watena   \n",
       "3  The singer's voice      164                            Ru Sara   \n",
       "4  The singer's voice        6              Adanne Ay Sudu Manike   \n",
       "\n",
       "               Artist                                               song  \n",
       "0         Dhanith Sri                          Sandaganawa - Dhanith Sri  \n",
       "1   Victor Rathnayaka  Api hagum walata ida dee mohothak - Victor Rat...  \n",
       "2            6th Lane                    Mandaram Wahi Watena - 6th Lane  \n",
       "3  Bathiya & Santhush                       Ru Sara - Bathiya & Santhush  \n",
       "4     H. R. Jothipala            Adanne Ay Sudu Manike - H. R. Jothipala  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge title and artist to a one column\n",
    "df_merge['song'] = df_merge[['Title', 'Artist']].apply(lambda x: ' - '.join(x), axis=1)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>hours_spending</th>\n",
       "      <th>musical_aspect</th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "      <th>listened_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>174</td>\n",
       "      <td>Sandaganawa</td>\n",
       "      <td>Dhanith Sri</td>\n",
       "      <td>Sandaganawa - Dhanith Sri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>220</td>\n",
       "      <td>Api hagum walata ida dee mohothak</td>\n",
       "      <td>Victor Rathnayaka</td>\n",
       "      <td>Api hagum walata ida dee mohothak - Victor Rat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>25 - 34</td>\n",
       "      <td>Male</td>\n",
       "      <td>Working</td>\n",
       "      <td>2 - 3</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>221</td>\n",
       "      <td>Mandaram Wahi Watena</td>\n",
       "      <td>6th Lane</td>\n",
       "      <td>Mandaram Wahi Watena - 6th Lane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10003</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>164</td>\n",
       "      <td>Ru Sara</td>\n",
       "      <td>Bathiya &amp; Santhush</td>\n",
       "      <td>Ru Sara - Bathiya &amp; Santhush</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10004</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Male</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>6</td>\n",
       "      <td>Adanne Ay Sudu Manike</td>\n",
       "      <td>H. R. Jothipala</td>\n",
       "      <td>Adanne Ay Sudu Manike - H. R. Jothipala</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id age_group  gender         profession hours_spending  \\\n",
       "0    10001   18 - 24  Female            Student          0 - 1   \n",
       "1    10001   18 - 24  Female            Student          0 - 1   \n",
       "2    10002   25 - 34    Male            Working          2 - 3   \n",
       "3    10003   18 - 24  Female  Software Engineer    more than 5   \n",
       "4    10004   18 - 24    Male  software engineer    more than 5   \n",
       "\n",
       "       musical_aspect  song_id                              Title  \\\n",
       "0         Tempo/speed      174                        Sandaganawa   \n",
       "1         Tempo/speed      220  Api hagum walata ida dee mohothak   \n",
       "2  The singer's voice      221               Mandaram Wahi Watena   \n",
       "3  The singer's voice      164                            Ru Sara   \n",
       "4  The singer's voice        6              Adanne Ay Sudu Manike   \n",
       "\n",
       "               Artist                                               song  \\\n",
       "0         Dhanith Sri                          Sandaganawa - Dhanith Sri   \n",
       "1   Victor Rathnayaka  Api hagum walata ida dee mohothak - Victor Rat...   \n",
       "2            6th Lane                    Mandaram Wahi Watena - 6th Lane   \n",
       "3  Bathiya & Santhush                       Ru Sara - Bathiya & Santhush   \n",
       "4     H. R. Jothipala            Adanne Ay Sudu Manike - H. R. Jothipala   \n",
       "\n",
       "   listened_song  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['listened_song'] = np.ones((441,), dtype=int)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playlist based on user favourites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_matrix(user_listen, songs):\n",
    "    ratings = pd.merge(user_listen, songs.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")\n",
    "    ratings['listened_song'] = np.ones((441,), dtype=int)\n",
    "    \n",
    "    # pivot ratings into song features\n",
    "    df_song_features = ratings.pivot(\n",
    "        index='song_id',\n",
    "        columns='user_id',\n",
    "        values='listened_song'\n",
    "    ).fillna(0)\n",
    "\n",
    "    return df_song_features\n",
    "\n",
    "def sparse_matrix(user_listen, songs):\n",
    "    df_song_features = user_item_matrix(user_listen, songs)\n",
    "    user_item_mat = csr_matrix(df_song_features.values)\n",
    "    return user_item_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_idx_mapping(user_listen, songs):\n",
    "    df_song_features = user_item_matrix(user_listen, songs)\n",
    "    song_to_idx = {\n",
    "    song: i for i, song in \n",
    "    enumerate(list(songs.set_index('song_id').loc[df_song_features.index].Title))\n",
    "    }\n",
    "    return song_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_model(user_listen, songs):\n",
    "    model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "    song_user_mat_sparse = sparse_matrix(user_listen, songs)\n",
    "    model_knn.fit(song_user_mat_sparse)\n",
    "    return model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_song, verbose=True):\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. \n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "    fav_movie: str, name of user input movie\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_song.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPG_recommendation(model_knn, data, mapper, fav_song, n_recommendations):\n",
    "    \"\"\"\n",
    "    return top n similar movie recommendations based on user's input movie\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_knn: sklearn model, knn model\n",
    "    data: movie-user matrix\n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "    fav_movie: str, name of user input movie\n",
    "    n_recommendations: int, top n recommendations\n",
    "    Return\n",
    "    ------\n",
    "    list of top n similar movie recommendations\n",
    "    \"\"\"\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    # get input movie index\n",
    "    print('You have input movie:', fav_song)\n",
    "    idx = fuzzy_matching(mapper, fav_song, verbose=True)\n",
    "    \n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    \n",
    "    raw_recommends = sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_song))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input movie: Ru Sara\n",
      "Found possible matches in our database: ['Ru Sara']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Ru Sara:\n",
      "1: Ran wan mal dam, with distance of 1.0\n",
      "2: Adaren (Lanwenna Hithuwata), with distance of 1.0\n",
      "3: Sinha Lokaye Sinhaya, with distance of 1.0\n",
      "4: Rahath himiwaru, with distance of 1.0\n",
      "5: Galana ganga, with distance of 1.0\n",
      "6: Akeekaru pem kathawak, with distance of 1.0\n",
      "7: Husmath unui, with distance of 1.0\n",
      "8: Hama deyak pene, with distance of 1.0\n",
      "9: Ulkapathayak, with distance of 1.0\n",
      "10: Sansara Sihine , with distance of 1.0\n"
     ]
    }
   ],
   "source": [
    "my_favorite = 'Ru Sara'\n",
    "\n",
    "DPG_recommendation(\n",
    "    model_knn=KNN_model(user_listen, songs),\n",
    "    data=sparse_matrix(user_listen, songs),\n",
    "    fav_song=my_favorite,\n",
    "    mapper=song_idx_mapping(user_listen, songs),\n",
    "    n_recommendations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top-N recommendation playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(df_merge, category):\n",
    "    # get a count of user_ids for each unique song as recommendation score\n",
    "    data_grouped = df_merge.groupby(['song']).agg({category: 'count'}).reset_index()\n",
    "    data_grouped.rename(columns = {'user_id': 'score'},inplace=True)\n",
    "\n",
    "    # Sort the songs based upon recommendation score\n",
    "    data_sort = data_grouped.sort_values(['score', 'song'], ascending = [0,1])\n",
    "\n",
    "    # Generate a recommendation rank based upon score\n",
    "    data_sort['Rank'] = data_sort['score'].rank(ascending=0, method='first')\n",
    "\n",
    "    # Get the top 10 recommendations\n",
    "    popularity_recommendations = data_sort.head(10) \n",
    "    return popularity_recommendations\n",
    "\n",
    "def top_N_recommendations(df_merge, category):\n",
    "    user_recommendations = create(df_merge, category)\n",
    "    #Add column for which the recommendations are being generated\n",
    "    #user_recommendations['user_id'] = category\n",
    "    \n",
    "    cols = user_recommendations.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    user_recommendations = user_recommendations[cols]\n",
    "    user_recommendations.reset_index(drop=True, inplace = True)\n",
    "    return user_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>song</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sandaganawa - Dhanith Sri</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Kuweni  - Ridma Weerawardena ft Dinupa Kodagoda</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pandama - Danith Dri</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sandanari - Harsha Withanage</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Prathihari - Supun Perera</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Nura wasanthe - Nadeemal Perera</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Perawadanak - Sanuka Wickramasinghe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Chandrayan Pidu Kiranak Sagawala Horen - Daddy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Kaulu Piyan Path Wahanna - Kasun Kalhara</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Radhawani - Supun Perera</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             song  score\n",
       "0   1.0                        Sandaganawa - Dhanith Sri     18\n",
       "1   2.0  Kuweni  - Ridma Weerawardena ft Dinupa Kodagoda     16\n",
       "2   3.0                             Pandama - Danith Dri     14\n",
       "3   4.0                     Sandanari - Harsha Withanage      9\n",
       "4   5.0                        Prathihari - Supun Perera      8\n",
       "5   6.0                  Nura wasanthe - Nadeemal Perera      7\n",
       "6   7.0              Perawadanak - Sanuka Wickramasinghe      7\n",
       "7   8.0   Chandrayan Pidu Kiranak Sagawala Horen - Daddy      5\n",
       "8   9.0         Kaulu Piyan Path Wahanna - Kasun Kalhara      5\n",
       "9  10.0                         Radhawani - Supun Perera      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_N_recommendations(df_merge = df_merge,\n",
    "                     category = 'user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playist based on user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique items (songs) corresponding to a given user\n",
    "def get_user_items(user_id):\n",
    "    user_data = df_merge[df_merge['user_id'] == user_id]\n",
    "    user_items = list(user_data['song'].unique())\n",
    "    return user_items\n",
    "    \n",
    "# Get unique users for a given item (song)\n",
    "def get_item_users(song):\n",
    "    item_data = df_merge[df_merge['song'] == song]\n",
    "    item_users = set(item_data['user_id'].unique())\n",
    "    return item_users\n",
    "    \n",
    "# Get unique items (songs) in the training data\n",
    "def get_all_items_train_data():\n",
    "    all_items = list(df_merge['song'].unique())\n",
    "    return all_items\n",
    "\n",
    "def get_item_users_by_title(Title):\n",
    "    item_data = df_merge[df_merge['Title'] == Title]\n",
    "    item_users_ = set(item_data['user_id'].unique())\n",
    "    return item_users_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = songs \n",
    "song_name = music.Title.values\n",
    "song_name_clean = [re.sub(r'[^\\w]', ' ', str(item))for item in song_name]\n",
    "song_name_clean = [re.sub(r\" \\d+\", '', str(item.strip())) for item in song_name_clean]\n",
    "\n",
    "sentences = list()\n",
    "for item in song_name_clean:\n",
    "    sentences.append(item.split())\n",
    "unique_sentence = np.unique(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate similar songs for new items\n",
    "def generate_similars(song_name):\n",
    "    \n",
    "    # load the trained model\n",
    "    model = FastText.load('word2vec.model')\n",
    "    \n",
    "    # split the song title\n",
    "    tokens = song_name.split() \n",
    "    \n",
    "    suggestions = []\n",
    "    \n",
    "    # check for most similar items form the model\n",
    "    suggestions.append(model.wv.most_similar(positive=tokens, topn=10))\n",
    "    \n",
    "    predictions = []\n",
    "    for l in range(len(suggestions[0])):\n",
    "        for i in range(len(unique_sentence)):\n",
    "            for j in range(len(unique_sentence[i])):\n",
    "                if unique_sentence[i][j] == suggestions[0][l][0]:\n",
    "    #                 print(unique_sentence[i])\n",
    "                    s = ' '\n",
    "                    word = s.join(unique_sentence[i])\n",
    "    #                 print(word)\n",
    "                    predictions.append(word)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def recommend_new_items(df_merge, user_id, new_song):\n",
    "    \n",
    "    predictions = generate_similars(new_song)\n",
    "    for item in predictions:\n",
    "        for value in get_item_users_by_title(item):\n",
    "            if value == user_id:\n",
    "                return new_song\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sarage Asille'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_item = recommend_new_items(df_merge, 10129, 'Sarage Asille')\n",
    "new_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct cooccurence matrix\n",
    "def construct_cooccurence_matrix(user_songs, all_songs, df_merge):\n",
    "    user_songs_users = []\n",
    "    for i in range(0, len(user_songs)):\n",
    "        user_songs_users.append(get_item_users(user_songs[i]))\n",
    "            \n",
    "        cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_songs), len(all_songs))), float)\n",
    "        \n",
    "    for i in range(0, len(all_songs)):\n",
    "        # Calculate unique listeners (users) of song (item) i\n",
    "        songs_i_data = df_merge[df_merge['song'] == all_songs[i]]\n",
    "        users_i = set(songs_i_data['user_id'].unique())\n",
    "#         print(songs_i_data)\n",
    "#         print(users_i)\n",
    "            \n",
    "        for j in range(0, len(user_songs)):\n",
    "            # Get unique listeners (users) of song (item) j\n",
    "            users_j = user_songs_users[j]\n",
    "                \n",
    "            # Calculate intersection of listeners of songs i and j\n",
    "            users_intersection = users_i.intersection(users_j)\n",
    "                \n",
    "            # Calculate cooccurence_matrix[i,j] as Jaccard Index\n",
    "            if len(users_intersection) != 0:\n",
    "                # Calculate union of listeners of songs i and j\n",
    "                users_union = users_i.union(users_j)\n",
    "                    \n",
    "                cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n",
    "                \n",
    "            else:\n",
    "                cooccurence_matrix[j,i] = 0\n",
    "                    \n",
    "    return cooccurence_matrix\n",
    "    \n",
    "# Use the cooccurence matrix to make top recommendations\n",
    "def generate_top_recommendations(user_id, cooccurence_matrix, all_songs, user_songs, new_song = None):\n",
    "    print(\"Non zero values in cooccurence_matrix :%d\" % np.count_nonzero(cooccurence_matrix))\n",
    "        \n",
    "    # Calculate a weighted average of the scores in cooccurence matrix for all user songs.\n",
    "    user_sim_scores = cooccurence_matrix.sum(axis=0)/float(cooccurence_matrix.shape[0])\n",
    "    user_sim_scores = np.array(user_sim_scores)[0].tolist()\n",
    "        \n",
    "    # Sort the indices of user_sim_scores based upon their value Also maintain the corresponding score\n",
    "    sort_index = sorted(((e,i) for i,e in enumerate(list(user_sim_scores))), reverse=True)\n",
    "    \n",
    "    # Create a dataframe from the following\n",
    "    columns = ['user_id', 'song', 'score', 'rank']\n",
    "    # index = np.arange(1) # array of numbers for the number of samples\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "        \n",
    "    # Fill the dataframe with top 10 item based recommendations\n",
    "    rank = 1 \n",
    "    for i in range(0,len(sort_index)):\n",
    "        if ~np.isnan(sort_index[i][0]) and all_songs[sort_index[i][1]] not in user_songs and rank <= 10:\n",
    "            df.loc[len(df)]=[user_id,all_songs[sort_index[i][1]],sort_index[i][0],rank]\n",
    "            rank = rank+1\n",
    "        \n",
    "        # Handle the case where there are no recommendations\n",
    "    if df.shape[0] == 0:\n",
    "        print(\"The current user has no songs for training the item similarity based recommendation model.\")\n",
    "        return -1\n",
    "    else:\n",
    "        if (new_song != None):\n",
    "            df = df.append({'user_id' : user_id, 'song' : new_song} , ignore_index=True)\n",
    "            return df\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "\n",
    "    # Use the item similarity based recommender system model to make recommendations\n",
    "def recommend_songs(user_id, df_merge, new_song = None):\n",
    "    user_songs = get_user_items(user_id)    \n",
    "    print(\"No. of unique songs for the user: %d\" % len(user_songs))\n",
    " \n",
    "    all_songs = get_all_items_train_data()\n",
    "        \n",
    "    print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "    \n",
    "    cooccurence_matrix = construct_cooccurence_matrix(user_songs, all_songs, df_merge)\n",
    "\n",
    "    if (new_song != None):\n",
    "        new_item = recommend_new_items(df_merge, user_id, new_song)\n",
    "        df_recommendations = generate_top_recommendations(user_id, cooccurence_matrix, all_songs, user_songs, new_item)\n",
    "    else:\n",
    "        df_recommendations = generate_top_recommendations(user_id, cooccurence_matrix, all_songs, user_songs)\n",
    "                \n",
    "                \n",
    "    return df_recommendations\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of unique songs for the user: 2\n",
      "no. of unique songs in the training set: 227\n",
      "Non zero values in cooccurence_matrix :24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>Pandama - Danith Dri</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>Saragaye (Niya Rata Mawanawa) - Sanuka Wickram...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>Kuweni  - Ridma Weerawardena ft Dinupa Kodagoda</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10001</td>\n",
       "      <td>Prathihari - Supun Perera</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10001</td>\n",
       "      <td>Oba apple malak wage - Amarasiri Peiris</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10001</td>\n",
       "      <td>Mage Unmade - Sangeeth Iddamalgoda</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10001</td>\n",
       "      <td>Runawiye - DKM ft. YAKA</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10001</td>\n",
       "      <td>Samawak na - Cairo Rich</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10001</td>\n",
       "      <td>Hitha Mithuru Sulaga  - Victor Rathnayaka</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10001</td>\n",
       "      <td>Surath Suwaya(Nil Warala Pura) - Supun Perera ...</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id                                               song     score rank\n",
       "0   10001                               Pandama - Danith Dri  0.051724    1\n",
       "1   10001  Saragaye (Niya Rata Mawanawa) - Sanuka Wickram...  0.050000    2\n",
       "2   10001    Kuweni  - Ridma Weerawardena ft Dinupa Kodagoda  0.048387    3\n",
       "3   10001                          Prathihari - Supun Perera  0.041667    4\n",
       "4   10001            Oba apple malak wage - Amarasiri Peiris  0.027778    5\n",
       "5   10001                 Mage Unmade - Sangeeth Iddamalgoda  0.027778    6\n",
       "6   10001                            Runawiye - DKM ft. YAKA  0.027778    7\n",
       "7   10001                            Samawak na - Cairo Rich  0.027778    8\n",
       "8   10001          Hitha Mithuru Sulaga  - Victor Rathnayaka  0.027778    9\n",
       "9   10001  Surath Suwaya(Nil Warala Pura) - Supun Perera ...  0.027778   10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_songs(user_id = 10001, df_merge = df_merge, new_song = 'Saragee Asille')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct cooccurence matrix\n",
    "# def construct_cooccurence_matrix(user_songs, all_songs, df_merge):\n",
    "#     user_songs_users = []\n",
    "#     for i in range(0, len(user_songs)):\n",
    "#         user_songs_users.append(get_item_users(user_songs[i]))\n",
    "            \n",
    "#         cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_songs), len(all_songs))), float)\n",
    "        \n",
    "#     for i in range(0, len(all_songs)):\n",
    "#         # Calculate unique listeners (users) of song (item) i\n",
    "#         songs_i_data = df_merge[df_merge['song'] == all_songs[i]]\n",
    "#         users_i = set(songs_i_data['user_id'].unique())\n",
    "#         print(songs_i_data)\n",
    "#         print(users_i)\n",
    "            \n",
    "#         for j in range(0, len(user_songs)):\n",
    "#             # Get unique listeners (users) of song (item) j\n",
    "#             users_j = user_songs_users[j]\n",
    "                \n",
    "#             # Calculate intersection of listeners of songs i and j\n",
    "#             users_intersection = users_i.intersection(users_j)\n",
    "                \n",
    "#             # Calculate cooccurence_matrix[i,j] as Jaccard Index\n",
    "#             if len(users_intersection) != 0:\n",
    "#                 # Calculate union of listeners of songs i and j\n",
    "#                 users_union = users_i.union(users_j)\n",
    "                    \n",
    "#                 cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n",
    "                \n",
    "#             else:\n",
    "#                 cooccurence_matrix[j,i] = 0\n",
    "                    \n",
    "#     return cooccurence_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# content-based feeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the music data, we have \"song_id\", \"title\", \"release\", \"artist_name\", \"year\"\n",
    "\n",
    "We can first use Word2Vec to convert the title and artist name into vectors, then with some normalization, combining it with year, we can use knn to generate the song embedding (V) for unseen item and feed it back to the collobrative model in order to recommend unseen songs to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Aa Ra Sulan</td>\n",
       "      <td>Nirosha Virajini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>Aale katha</td>\n",
       "      <td>Kalpana Nayanamadu, Shermaine Willis ft Iraj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Ada Nam Ma Hada Iwasum Na</td>\n",
       "      <td>Raveen Kanishka &amp; Kalpana Kavindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Ada Thaniyen Ma Hadanne Na Ma</td>\n",
       "      <td>Shihan Mihiranga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Adambarai Baluwama Nam</td>\n",
       "      <td>Surani De Mel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                          Title  \\\n",
       "0        2                    Aa Ra Sulan   \n",
       "1      283                     Aale katha   \n",
       "2        3      Ada Nam Ma Hada Iwasum Na   \n",
       "3        4  Ada Thaniyen Ma Hadanne Na Ma   \n",
       "4        5         Adambarai Baluwama Nam   \n",
       "\n",
       "                                         Artist  \n",
       "0                              Nirosha Virajini  \n",
       "1  Kalpana Nayanamadu, Shermaine Willis ft Iraj  \n",
       "2             Raveen Kanishka & Kalpana Kavindi  \n",
       "3                              Shihan Mihiranga  \n",
       "4                                 Surani De Mel  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of strings, one for each title\n",
    "# titles_list = [title for title in songs['Title']]\n",
    "# big_title_string = ' '.join(titles_list)\n",
    "\n",
    "# # Tokenize the string into words\n",
    "# tokens = word_tokenize(big_title_string)\n",
    "\n",
    "# # Remove non-alphabetic tokens, such as punctuation\n",
    "# words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "# # Print first 10 words\n",
    "# words[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_list = [model[word] for word in words if word in model.wv.vocab]\n",
    "\n",
    "# # Create a list of the words corresponding to these vectors\n",
    "# words_filtered = [word for word in words if word in model.wv.vocab]\n",
    "\n",
    "# # Zip the words together with their vector representations\n",
    "# word_vec_zip = zip(words_filtered, vector_list)\n",
    "\n",
    "# # Cast to a dict so we can turn it into a DataFrame\n",
    "# word_vec_dict = dict(word_vec_zip)\n",
    "# df = pd.DataFrame.from_dict(word_vec_dict, orient='index')\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist = set(song_df.artist_name.values)\n",
    "music = songs \n",
    "song_name = music.Title.values\n",
    "song_name_clean = [re.sub(r'[^\\w]', ' ', str(item))for item in song_name]\n",
    "song_name_clean = [re.sub(r\" \\d+\", '', str(item.strip())) for item in song_name_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "for item in song_name_clean:\n",
    "    sentences.append(item.split())\n",
    "unique_sentence = np.unique(sentences) # build the model on all unique sentence but not all sentence to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Aa', 'Ra', 'Sulan']), list(['Aale', 'katha']),\n",
       "       list(['Ada', 'Nam', 'Ma', 'Hada', 'Iwasum', 'Na']),\n",
       "       list(['Ada', 'Thaniyen', 'Ma', 'Hadanne', 'Na', 'Ma']),\n",
       "       list(['Adambarai', 'Baluwama', 'Nam']),\n",
       "       list(['Adanne', 'Ay', 'Sudu', 'Manike']),\n",
       "       list(['Adaraneeya', 'Neranjana']), list(['Adaraya', 'Ayai']),\n",
       "       list(['Adare', 'sithum']), list(['Adarema', 'Geethayak']),\n",
       "       list(['Adaren', 'Lanwenna', 'Hithuwata']),\n",
       "       list(['Aduru', 'kutiya', 'thula']), list(['Ae']),\n",
       "       list(['Ahasin', 'eha']), list(['Ahasin', 'polowata']),\n",
       "       list(['Ai', 'Kale', 'Adare']),\n",
       "       list(['Ai', 'kale', 'mulu', 'hadinma']),\n",
       "       list(['Akeekaru', 'pem', 'kathawak']), list(['Alawanthakam']),\n",
       "       list(['Alen', 'Ma']), list(['Alen', 'Wela', 'Ganna']),\n",
       "       list(['Amma', 'Sandaki']), list(['Anagathaye']),\n",
       "       list(['Ananthayata', 'Yana', 'Para', 'Dige']), list(['Ananthaye']),\n",
       "       list(['Anatha', 'maruthe']),\n",
       "       list(['Api', 'hagum', 'walata', 'ida', 'dee', 'mohothak']),\n",
       "       list(['Api', 'kauruda']),\n",
       "       list(['Arabumama', 'Kadulak', 'Wela', 'Ma', 'Bala', 'Iddi']),\n",
       "       list(['Atha', 'Kadukara', 'Himau', 'Arane']),\n",
       "       list(['Atha', 'Ran', 'Wiman', 'Thulin', 'Pata', 'Selayen', 'Sadi']),\n",
       "       list(['Athinwath', 'atha']),\n",
       "       list(['Athithaya', 'Sihinayak', 'Pamanai']), list(['Athsana']),\n",
       "       list(['Awado', 'Sansare', 'Ma', 'Ha', 'Badee']),\n",
       "       list(['Awathan', 'hade']),\n",
       "       list(['Ay', 'Kale', 'Mulu', 'Hadinma', 'Oba', 'Mata', 'Adare']),\n",
       "       list(['Ayage', 'Sinaha']), list(['Baila', 'Gamuda']),\n",
       "       list(['Billa']), list(['Boralu', 'anena']), list(['Chain']),\n",
       "       list(['Chakithaya']), list(['Chandani', 'Payala']),\n",
       "       list(['Chandrayan', 'Pidu', 'Kiranak', 'Sagawala', 'Horen']),\n",
       "       list(['Channa', 'Kinnaravi']), list(['Ciao', 'Malli']),\n",
       "       list(['Cuore', 'Nero', 'Italian']), list(['Daasin', 'Paa']),\n",
       "       list(['Daffodil', 'mala']), list(['Daiwaye', 'Saradamin']),\n",
       "       list(['Das', 'Piyan', 'Wesena', 'Asille']),\n",
       "       list(['Dasama', 'riddana']),\n",
       "       list(['Dasin', 'Pa', 'Ma', 'Ingi', 'Maru', 'Dewliye']),\n",
       "       list(['Dedunna', 'Sedi']), list(['Denuwan', 'piya']),\n",
       "       list(['Dewadaththa']), list(['Dewagana']),\n",
       "       list(['Dewiyo', 'Wadee']), list(['Dinuma', 'Paraduma']),\n",
       "       list(['Diwasaravi']),\n",
       "       list(['Duka', 'Danna', 'Nisai', 'Mulu', 'Hadinma']),\n",
       "       list(['Duwe', 'Nuba', 'Mage', 'Pranayai']),\n",
       "       list(['Eka', 'wasanthayaka']), list(['Eka', 'yaye']),\n",
       "       list(['Esdeka', 'Pura', 'Yannam', 'Yannam']),\n",
       "       list(['Etha', 'kandukara']), list(['Eya', 'Meya']),\n",
       "       list(['Galana', 'ganga']), list(['Gamata', 'Kalin', 'Hiru']),\n",
       "       list(['Gamen', 'Liyumak', 'Awilla']),\n",
       "       list(['Gassana', 'Dagha', 'Malla']), list(['Gayamu', 'dawasaka']),\n",
       "       list(['Golu', 'Daruwek', 'Una', 'Kiya']), list(['Gomara', 'mala']),\n",
       "       list(['Gum', 'Nade']), list(['Hama', 'deyak', 'pene']),\n",
       "       list(['Hanguman']),\n",
       "       list(['Hanthana', 'Sihine', 'Bala', 'Walapemi']),\n",
       "       list(['Hanthanata', 'Payana', 'Sanda']), list(['Hawasaka', 'Ma']),\n",
       "       list(['Heena', 'Maka']), list(['Hethuwa']),\n",
       "       list(['Hey', 'Kakulee']), list(['Hiinamaka']),\n",
       "       list(['Hinahenne', 'Mung', 'Mey', 'Wil', 'Theeraye']),\n",
       "       list(['Hini', 'peththta']), list(['Hiru', 'Mal']),\n",
       "       list(['Hitha', 'Assata']), list(['Hitha', 'Dura', 'Handa']),\n",
       "       list(['Hitha', 'Hiriwetunado']),\n",
       "       list(['Hitha', 'Mithuru', 'Sulaga']),\n",
       "       list(['Hitha', 'Nambara', 'Thaleta']),\n",
       "       list(['Hitha', 'Wawannema', 'Na']),\n",
       "       list(['Hithin', 'yana', 'aya', 'athin', 'alla', 'nawathtannata', 'be']),\n",
       "       list(['Husmath', 'unui']),\n",
       "       list(['I', 'can', 't', 'Keep', 'Lying']), list(['Iduwari']),\n",
       "       list(['Iki', 'Gasa', 'Hadana', 'Atheethayaka']),\n",
       "       list(['Iwasaida', 'Manda']), list(['Iwasanna', 'Bari', 'Tharam']),\n",
       "       list(['Jeewithaye', 'Sundara', 'Bawa']),\n",
       "       list(['Kaada', 'Raja', 'Revised', 'Mix']), list(['Kaasi']),\n",
       "       list(['Kalakanni', 'loke']), list(['Kalu', 'Hitha']),\n",
       "       list(['Kamaniya']),\n",
       "       list(['Kampa', 'Nowan', 'Mahamaya', 'Nissara', 'Wu', 'Sansaraye']),\n",
       "       list(['Kandulu', 'irthuwe']), list(['Katawath', 'Ba']),\n",
       "       list(['Kath', 'Kawuruwath', 'Nathi', 'Bawa']),\n",
       "       list(['Kaulu', 'Piyan', 'Path', 'Wahanna']),\n",
       "       list(['Kawada', 'Ho', 'Laga', 'Nathi', 'Bawa', 'Danenawa']),\n",
       "       list(['Kawikaariye']), list(['Kawiya', 'Oba']),\n",
       "       list(['Kiri', 'Kodu', 'Hithata']),\n",
       "       list(['Ko', 'ma', 'pathu', 'nube', 'adare']),\n",
       "       list(['Kohe', 'Yannada', 'Ma']), list(['Kshemaye', 'nagare']),\n",
       "       list(['Kuweni']), list(['Labhadiye']), list(['Landune']),\n",
       "       list(['Lanka', 'Matha']),\n",
       "       list(['Liyathambara', 'Mudu', 'Kusumaki', 'Aae']),\n",
       "       list(['Lokayen', 'Yamu']),\n",
       "       list(['Lu', 'Numba', 'Nomathi', 'Dihawaka']),\n",
       "       list(['Ma', 'Hadawala']),\n",
       "       list(['Ma', 'Oba', 'Hamuwana', 'Dinaye']),\n",
       "       list(['Mage', 'Kiya', 'Eth', 'Wela']), list(['Mage', 'Unmade']),\n",
       "       list(['Mage', 'ne']), list(['Mage', 'punchi', 'rosa', 'male']),\n",
       "       list(['Mage', 'sihine', 'obai']),\n",
       "       list(['Maha', 'Warusawata', 'Pasuwa', 'Nagena', 'Sanda']),\n",
       "       list(['Mahamaaya']), list(['Mal', 'Madahasa']),\n",
       "       list(['Mal', 'Mitak', 'Thiyanna']), list(['Mal', 'pan', 'podak']),\n",
       "       list(['Malak', 'Une', 'Ai', 'Numba', 'Mata']),\n",
       "       list(['Malakuth', 'thibuna']),\n",
       "       list(['Man', 'ithaliye', 'thani', 'una']), list(['Mana', 'Bandu']),\n",
       "       list(['Manamali']), list(['Mandakini']),\n",
       "       list(['Mandaram', 'Wahi', 'Watena']), list(['Mankiniye']),\n",
       "       list(['Marambari', 'Kola', 'Wee']), list(['Maraya']),\n",
       "       list(['Marunu', 'Hithe']), list(['Master', 'sir']),\n",
       "       list(['Mata', 'Rawana']), list(['Math', 'mage', 'hitha']),\n",
       "       list(['Mathakai', 'Eda']), list(['Mathakaida', 'ada', 'wage']),\n",
       "       list(['Mathakaya', 'Asurin', 'Sihiyata', 'Gannata']),\n",
       "       list(['Mawena']), list(['Mayam', 'Kalawe']), list(['Mayawee']),\n",
       "       list(['Me', 'Avurudu', 'Kale']), list(['Me', 'Hitha', 'Thaniyen']),\n",
       "       list(['Me', 'Sanda', 'Unath', 'Paya', 'Awith']),\n",
       "       list(['Me', 'Tharam', 'Siyumalida', 'Kalugal']),\n",
       "       list(['Me', 'diganthayeee']), list(['Me', 'mal', 'yaye']),\n",
       "       list(['Meeduma', 'Uthurana']), list(['Mey', 'Jeewithe']),\n",
       "       list(['Mihiravi']), list(['Mihirawa', 'Awa']),\n",
       "       list(['Mumunanawa']), list(['Muwa', 'muktha', 'latha']),\n",
       "       list(['Na', 'Thawath', 'Hithak']), list(['Nadagam', 'Geeya']),\n",
       "       list(['Nadee', 'Ganga', 'Tharanaye']),\n",
       "       list(['Nalawena', 'Sulagak']), list(['Nattami']),\n",
       "       list(['Natuwen', 'Gilihunu', 'Pinna', 'Malak']), list(['Naukawa']),\n",
       "       list(['Nawathi', 'Methekin']),\n",
       "       list(['Neela', 'Kobei', 'Rana', 'Adii']),\n",
       "       list(['Neela', 'Nimnaye']),\n",
       "       list(['Nethu', 'Kalma', 'Ma', 'Welai']), list(['Nethu', 'Saluna']),\n",
       "       list(['Nethu', 'dahan']), list(['Nimnawiye']),\n",
       "       list(['Ninda', 'Noyana', 'Handawe']), list(['Nirayase']),\n",
       "       list(['Niwaduwatath', 'Man', 'Dan', 'Sankawen']),\n",
       "       list(['Numbada', 'bimba']), list(['Nura', 'wasanthe']),\n",
       "       list(['Nurawee']), list(['Oba', 'Dakala']),\n",
       "       list(['Oba', 'Dutu', 'E', 'Mul', 'Dine']),\n",
       "       list(['Oba', 'Enna', 'Aye']),\n",
       "       list(['Oba', 'Ha', 'Mema', 'Athinath', 'Aran']),\n",
       "       list(['Oba', 'Heenayak', 'Wage', 'Hadu', 'Wessak', 'Aran']),\n",
       "       list(['Oba', 'Kamathi', 'Nam']), list(['Oba', 'Kauda']),\n",
       "       list(['Oba', 'Magemai']), list(['Oba', 'Nisa']),\n",
       "       list(['Oba', 'apple', 'malak', 'wage']),\n",
       "       list(['Obage', 'Mathaken']), list(['Oya', 'Magenam']),\n",
       "       list(['Paaren']), list(['Pamawee', 'Pipunu', 'Mal', 'Suwandai']),\n",
       "       list(['Pandama']), list(['Pawena', 'Loke']),\n",
       "       list(['Pawena', 'kodu', 'akase']),\n",
       "       list(['Paya', 'Ena', 'Sanda', 'Watha', 'Manaram']),\n",
       "       list(['Pera', 'Dinayaka', 'Ma', 'Pem', 'Kala', 'Yuwathiya']),\n",
       "       list(['Perada', 'Mawu', 'Sina']), list(['Perawadanak']),\n",
       "       list(['Pini', 'Binduwak', 'Wennata', 'Asai']),\n",
       "       list(['Pinna', 'Male', 'Suda', 'Anna', 'Gihin', 'Wada']),\n",
       "       list(['Pitasakwala', 'Yaane']), list(['Piyawuna']),\n",
       "       list(['Prarthanawe']), list(['Prasiddiya', 'Ko']),\n",
       "       list(['Prathihari']), list(['Prema', 'sajjayanaya']),\n",
       "       list(['Premaye', 'wil', 'there']),\n",
       "       list(['Premayen', 'mana', 'ranjitha', 'we']),\n",
       "       list(['Ra', 'Ahasin', 'Wetena', 'Bindu', 'Bindu']),\n",
       "       list(['Ra', 'Pura', 'Payana', 'Tharuka']),\n",
       "       list(['Ra', 'Thisse', 'Awilla']), list(['Ra', 'ahase']),\n",
       "       list(['Raata', 'man']), list(['Radhawani']),\n",
       "       list(['Radical', 'paththini']),\n",
       "       list(['Rahase', 'Handana', 'Apa', 'Hagum']),\n",
       "       list(['Rahath', 'himiwaru']), list(['Rambari']),\n",
       "       list(['Ran', 'Dakaththen']), list(['Ran', 'Kurahan', 'Mala']),\n",
       "       list(['Ran', 'wan', 'mal', 'dam']), list(['Rangume']),\n",
       "       list(['Reta', 'Mang']), list(['Ridena', 'Noriddena']),\n",
       "       list(['Robarosiyan']), list(['Rodha', 'Bandila']),\n",
       "       list(['Ron', 'Podak']), list(['Rosa', 'Kalpna']),\n",
       "       list(['Ru', 'Sara']), list(['Runawiye']),\n",
       "       list(['Sada', 'Eliya', 'Gala', 'Ena']),\n",
       "       list(['Sadha', 'Ebennnepa']), list(['Sadha', 'Oba', 'Mage']),\n",
       "       list(['Sadha', 'Tharu', 'Mal', 'Mata', 'Dan', 'Dun']),\n",
       "       list(['Samawak', 'na']), list(['Sanda', 'Latha', 'Payala']),\n",
       "       list(['Sanda', 'Nawath', 'Kamak', 'Nathe']),\n",
       "       list(['Sanda', 'Thaniyama']), list(['Sanda', 'pahan', 'raye']),\n",
       "       list(['Sandaganawa']), list(['Sandanari']),\n",
       "       list(['Sandawathiya', 'Obai']), list(['Sansara', 'Sihine']),\n",
       "       list(['Sansaraye', 'ma']), list(['Sara', 'Sadhe']),\n",
       "       list(['Sara', 'Sihina', 'Rahase', 'Diwura', 'Kiya']),\n",
       "       list(['Saragaye', 'Niya', 'Rata', 'Mawanawa']),\n",
       "       list(['Saragee', 'Asille']), list(['Sasthara']),\n",
       "       list(['Sathanta', 'Kiyanna']),\n",
       "       list(['Seetha', 'Maruthe', 'Welemin', 'Es', 'Diha', 'Balan']),\n",
       "       list(['Seethala', 'Heene']),\n",
       "       list(['Senehasakata', 'Aruthak', 'Purawannata']),\n",
       "       list(['Sepalikawo']), list(['Sharadha']),\n",
       "       list(['Sihina', 'Lowe', 'Maya', 'Wethire']), list(['Sihinaya']),\n",
       "       list(['Sihine']), list(['Sikuru', 'Tharuwa', 'Raye']),\n",
       "       list(['Sinasenna']), list(['Singali', 'None']),\n",
       "       list(['Sinha', 'Lokaye', 'Sinhaya']),\n",
       "       list(['Sithin', 'Ma', 'Noseli']), list(['Siyumali']),\n",
       "       list(['Sonduru', 'Atheethaye', 'Nimala', 'Pathumawee']),\n",
       "       list(['Sonduru', 'Siththam']), list(['Soro']),\n",
       "       list(['Soya', 'Awa']), list(['Sudu', 'Gawma']),\n",
       "       list(['Sulagak', 'Wela', 'Oba', 'Soya', 'Enna', 'One']),\n",
       "       list(['Sulanga', 'Obada']),\n",
       "       list(['Surath', 'Suwaya', 'Nil', 'Warala', 'Pura']),\n",
       "       list(['Suwada', 'saban', 'anga', 'gaala']),\n",
       "       list(['Thanhawa', 'Pirila']), list(['Tharanaya']),\n",
       "       list(['Tharuka', 'Pelin', 'Eha']), list(['Thawa', 'dawasak']),\n",
       "       list(['Thurul', 'Wenna', 'Asai']),\n",
       "       list(['Tiken', 'Tika', 'Tiken', 'Tika']), list(['Ulkapathayak']),\n",
       "       list(['Unmada', 'Wu', 'Premadare']), list(['Unmada', 'chithra']),\n",
       "       list(['Unmadini', 'Hanguna']), list(['Unuhuma', 'Aradhana']),\n",
       "       list(['Wakkada', 'Langa', 'Kaluu']),\n",
       "       list(['Wala', 'thiryen', 'eha']),\n",
       "       list(['Walithara', 'Athare', 'Himihita', 'Basina']),\n",
       "       list(['Wasanthaye', 'Aga', 'Hamuwemu', 'Sonduriya']),\n",
       "       list(['Wasanthaye', 'Pipidena', 'Mal']), list(['Wassama']),\n",
       "       list(['Wassanayata', 'Atha', 'Wanala']),\n",
       "       list(['Wikasitha', 'Pem', 'Pokuru', 'Piyum']),\n",
       "       list(['Yaal', 'Panamen']), list(['Yakkun', 'Pitiyata'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create word2vec model\n",
    "# # Set values for NN parameters\n",
    "# num_features = 50    # Word vector dimensionality                      \n",
    "# min_word_count = 1                      \n",
    "# num_workers = 1      # Number of CPUs\n",
    "# context = 3          # Context window size; \n",
    "                                                                                                        \n",
    "# downsampling = 1e-3   # threshold for configuring which \n",
    "#                       # higher-frequency words are randomly downsampled\n",
    "\n",
    "# # Initialize and train the model \n",
    "# model_wv = gensim.models.Word2Vec(unique_sentence, workers=num_workers, \\\n",
    "#             size=num_features, min_count = min_word_count, \\\n",
    "#             window = context, sample = downsampling, sg = 1)\n",
    "\n",
    "# # model_wv.build_vocab(unique_sentence, progress_per=200)\n",
    "\n",
    "# # model_wv.train(unique_sentence, total_examples = model.corpus_count, \n",
    "# #             epochs=10, report_delay=1)\n",
    "\n",
    "# # If you don't plan to train the model any further, calling \n",
    "# # init_sims will make the model much more memory-efficient.\n",
    "# model_wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_wv.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(653, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = model[model.wv.vocab]\n",
    "\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0,\n",
    "#                               n_components=2, random_state=42).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similar_products(v, n = 6):\n",
    "#     products_dict =  {}\n",
    "#     # extract most similar products for the input vector\n",
    "#     ms = model.similar_by_vector(v, topn= n+1)[1:]\n",
    "    \n",
    "#     # extract name and similarity score of the similar products\n",
    "#     new_ms = []\n",
    "#     for j in ms:\n",
    "#         pair = (products_dict[j[0]][0], j[1])\n",
    "#         new_ms.append(pair)\n",
    "        \n",
    "#     return new_ms     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_wv.most_similar(u'Wawannema') # similar word to love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_wv.most_similar('Ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_wv.predict_output_word(['Saragi'], topn = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create word2vec model\n",
    "# Set values for NN parameters\n",
    "num_features = 50    # Word vector dimensionality                      \n",
    "min_word_count = 1                      \n",
    "num_workers = 1      # Number of CPUs\n",
    "context = 3          # Context window size; \n",
    "                                                                                                        \n",
    "downsampling = 1e-3   # threshold for configuring which \n",
    "                      # higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model_wv = FastText(workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, sg = 1)\n",
    "\n",
    "model_wv.build_vocab(sentences = unique_sentence)\n",
    "model_wv.train(sentences = unique_sentence,  total_examples=len(unique_sentence), epochs=10)\n",
    "\n",
    "model_wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv.save('word2vec.model')\n",
    "model = FastText.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Adarema', 0.5569604635238647),\n",
       " ('Adaren', 0.48059654235839844),\n",
       " ('mal', 0.459030419588089),\n",
       " ('Pokuru', 0.3751647472381592),\n",
       " ('Yaal', 0.3603614270687103),\n",
       " ('nube', 0.35141992568969727),\n",
       " ('Adaraneeya', 0.33996152877807617),\n",
       " ('Nathi', 0.3362344205379486),\n",
       " ('Sulagak', 0.32758551836013794),\n",
       " ('Pinna', 0.30353084206581116)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Adare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48059654"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('Adare', 'Adaren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00484305 -0.03475127 -0.00661441  0.05109205  0.02670166  0.02411269\n",
      "  0.01072268 -0.00809084  0.01354577 -0.04733701 -0.03353004  0.02331018\n",
      "  0.00455881  0.03103582  0.0403338  -0.00735925  0.03735436  0.01877754\n",
      "  0.06927647  0.01262611 -0.05566176  0.04455525  0.01797638  0.08560292\n",
      "  0.02440351 -0.02470134 -0.04367522 -0.01514639 -0.00401336 -0.04286401\n",
      " -0.04277678  0.03670257  0.06413483 -0.01559428  0.0487486   0.02490747\n",
      "  0.03766687  0.03939747  0.03528021  0.02880044  0.0327778  -0.00210523\n",
      "  0.0300089   0.03726153 -0.01770418  0.01076948  0.0094786  -0.03558464\n",
      "  0.0769246   0.00633751]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['Saragi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Arabumama', 0.374399870634079),\n",
       " ('Samawak', 0.36850494146347046),\n",
       " ('Rangume', 0.34819692373275757),\n",
       " ('Lanka', 0.345318466424942),\n",
       " ('mohothak', 0.3197134733200073),\n",
       " ('atha', 0.3117147386074066),\n",
       " ('Dun', 0.30848634243011475),\n",
       " ('Assata', 0.29812291264533997),\n",
       " ('Hadinma', 0.29117846488952637),\n",
       " ('Pitasakwala', 0.29103660583496094)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Asille')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Samawak', 0.4077220857143402),\n",
       " ('Rangume', 0.3338375687599182),\n",
       " ('Assata', 0.33264869451522827),\n",
       " ('Arabumama', 0.32684507966041565),\n",
       " ('Dun', 0.32256919145584106)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['Saragi', 'Asille'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Arabumama', 0.374399870634079),\n",
       "  ('Samawak', 0.36850494146347046),\n",
       "  ('Rangume', 0.34819692373275757),\n",
       "  ('Lanka', 0.345318466424942),\n",
       "  ('mohothak', 0.3197134733200073),\n",
       "  ('atha', 0.3117147386074066),\n",
       "  ('Dun', 0.30848634243011475),\n",
       "  ('Assata', 0.29812291264533997),\n",
       "  ('Hadinma', 0.29117846488952637),\n",
       "  ('Pitasakwala', 0.29103660583496094)]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions = []\n",
    "suggestions.append(model.most_similar('Asille'))\n",
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Arabumama', 0.374399870634079),\n",
       " ('Samawak', 0.36850494146347046),\n",
       " ('Rangume', 0.34819692373275757),\n",
       " ('Lanka', 0.345318466424942),\n",
       " ('mohothak', 0.3197134733200073),\n",
       " ('atha', 0.3117147386074066),\n",
       " ('Dun', 0.30848634243011475),\n",
       " ('Assata', 0.29812291264533997),\n",
       " ('Hadinma', 0.29117846488952637),\n",
       " ('Pitasakwala', 0.29103660583496094)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aale', 'katha']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabumama\n",
      "Samawak\n",
      "Rangume\n",
      "Lanka\n",
      "mohothak\n",
      "atha\n",
      "Dun\n",
      "Assata\n",
      "Hadinma\n",
      "Pitasakwala\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(suggestions[0])):\n",
    "    print(suggestions[0][i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabumama Kadulak Wela Ma Bala Iddi',\n",
       " 'Samawak na',\n",
       " 'Rangume',\n",
       " 'Lanka Matha',\n",
       " 'Api hagum walata ida dee mohothak',\n",
       " 'Athinwath atha',\n",
       " 'Sadha Tharu Mal Mata Dan Dun',\n",
       " 'Hitha Assata',\n",
       " 'Ay Kale Mulu Hadinma Oba Mata Adare',\n",
       " 'Duka Danna Nisai Mulu Hadinma',\n",
       " 'Pitasakwala Yaane']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for l in range(len(suggestions[0])):\n",
    "    for i in range(len(unique_sentence)):\n",
    "        for j in range(len(unique_sentence[i])):\n",
    "            if unique_sentence[i][j] == suggestions[0][l][0]:\n",
    "#                 print(unique_sentence[i])\n",
    "                s = ' '\n",
    "                word = s.join(unique_sentence[i])\n",
    "#                 print(word)\n",
    "                predictions.append(word)\n",
    "                \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>hours_spending</th>\n",
       "      <th>musical_aspect</th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "      <th>listened_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>174</td>\n",
       "      <td>Sandaganawa</td>\n",
       "      <td>Dhanith Sri</td>\n",
       "      <td>Sandaganawa - Dhanith Sri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Student</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Tempo/speed</td>\n",
       "      <td>220</td>\n",
       "      <td>Api hagum walata ida dee mohothak</td>\n",
       "      <td>Victor Rathnayaka</td>\n",
       "      <td>Api hagum walata ida dee mohothak - Victor Rat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>25 - 34</td>\n",
       "      <td>Male</td>\n",
       "      <td>Working</td>\n",
       "      <td>2 - 3</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>221</td>\n",
       "      <td>Mandaram Wahi Watena</td>\n",
       "      <td>6th Lane</td>\n",
       "      <td>Mandaram Wahi Watena - 6th Lane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10003</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>164</td>\n",
       "      <td>Ru Sara</td>\n",
       "      <td>Bathiya &amp; Santhush</td>\n",
       "      <td>Ru Sara - Bathiya &amp; Santhush</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10004</td>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Male</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>The singer's voice</td>\n",
       "      <td>6</td>\n",
       "      <td>Adanne Ay Sudu Manike</td>\n",
       "      <td>H. R. Jothipala</td>\n",
       "      <td>Adanne Ay Sudu Manike - H. R. Jothipala</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id age_group  gender         profession hours_spending  \\\n",
       "0    10001   18 - 24  Female            Student          0 - 1   \n",
       "1    10001   18 - 24  Female            Student          0 - 1   \n",
       "2    10002   25 - 34    Male            Working          2 - 3   \n",
       "3    10003   18 - 24  Female  Software Engineer    more than 5   \n",
       "4    10004   18 - 24    Male  software engineer    more than 5   \n",
       "\n",
       "       musical_aspect  song_id                              Title  \\\n",
       "0         Tempo/speed      174                        Sandaganawa   \n",
       "1         Tempo/speed      220  Api hagum walata ida dee mohothak   \n",
       "2  The singer's voice      221               Mandaram Wahi Watena   \n",
       "3  The singer's voice      164                            Ru Sara   \n",
       "4  The singer's voice        6              Adanne Ay Sudu Manike   \n",
       "\n",
       "               Artist                                               song  \\\n",
       "0         Dhanith Sri                          Sandaganawa - Dhanith Sri   \n",
       "1   Victor Rathnayaka  Api hagum walata ida dee mohothak - Victor Rat...   \n",
       "2            6th Lane                    Mandaram Wahi Watena - 6th Lane   \n",
       "3  Bathiya & Santhush                       Ru Sara - Bathiya & Santhush   \n",
       "4     H. R. Jothipala            Adanne Ay Sudu Manike - H. R. Jothipala   \n",
       "\n",
       "   listened_song  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saragi', 'Asille']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'Saragi Asille'\n",
    "l = string.split()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_users_by_title(Title):\n",
    "    item_data = df_merge[df_merge['Title'] == Title]\n",
    "    item_users = set(item_data['user_id'].unique())\n",
    "    return item_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10129, 10221}\n"
     ]
    }
   ],
   "source": [
    "print(get_item_users('Arabumama Kadulak Wela Ma Bala Iddi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate similar songs for new items\n",
    "def generate_similars(song_name):\n",
    "    \n",
    "    # load the trained model\n",
    "    model = FastText.load('word2vec.model')\n",
    "    \n",
    "    # split the song title\n",
    "    tokens = song_name.split() \n",
    "    \n",
    "    suggestions = []\n",
    "    \n",
    "    # check for most similar items form the model\n",
    "    suggestions.append(model.wv.most_similar(positive=tokens, topn=10))\n",
    "    \n",
    "    predictions = []\n",
    "    for l in range(len(suggestions[0])):\n",
    "        for i in range(len(unique_sentence)):\n",
    "            for j in range(len(unique_sentence[i])):\n",
    "                if unique_sentence[i][j] == suggestions[0][l][0]:\n",
    "    #                 print(unique_sentence[i])\n",
    "                    s = ' '\n",
    "                    word = s.join(unique_sentence[i])\n",
    "    #                 print(word)\n",
    "                    predictions.append(word)\n",
    "\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_new_items(song_name, user_id, df_merge):\n",
    "    \n",
    "    predictions = generate_similars(song_name)\n",
    "    for item in predictions:\n",
    "        for value in get_item_users_by_title(item):\n",
    "            if value == user_id:\n",
    "                return song_name\n",
    "            else:\n",
    "                continue\n",
    "    return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saragi Asille\n"
     ]
    }
   ],
   "source": [
    "print(recommend_new_items('Saragi Asille', 10129, df_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_distance (model, word,target_list , num) :\n",
    "#     cosine_dict ={}\n",
    "#     word_list = []\n",
    "#     a = model[word]\n",
    "#     for item in target_list :\n",
    "#         for i in item:\n",
    "#             if i != word :\n",
    "#                 b = model [i]\n",
    "#                 cos_sim = np.dot(a, b)/(LA.norm(a)*LA.norm(b))\n",
    "#                 cosine_dict[i] = cos_sim\n",
    "#     dist_sort=sorted(cosine_dict.items(), key=lambda dist: dist[1],reverse = True) ## in Descedning order \n",
    "#     for item in dist_sort:\n",
    "#         word_list.append((item[0], item[1]))\n",
    "#     return word_list[0:num]\n",
    "\n",
    "# cosine_distance (model_wv,'Adare',unique_sentence,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/cisco-emerge/creating-semantic-representations-of-out-of-vocabulary-words-for-common-nlp-tasks-842dbdafba18\n",
    "# https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3\n",
    "# https://pathmind.com/wiki/word2vec\n",
    "# https://github.com/manasRK/word2vec-recommender/blob/master/loadReviewModel.py\n",
    "# https://medium.com/building-creative-market/word2vec-inspired-recommendations-in-production-f2c6a6b5b0bf\n",
    "# https://arxiv.org/pdf/1601.01356.pdf\n",
    "# https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word-727b6cf723cf\n",
    "# https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
    "# https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92?#702d\n",
    "# https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484\n",
    "# https://github.com/YIZHE12/music_recom/blob/master/music_recommendation_binary.ipynb\n",
    "# https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751\n",
    "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "# https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the song title one by and one and average the word vector is too time-consuming, we can take advantage of the GPU by building a neural network model and fix the weights as the Word2Vec weights to convert our data to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sentences\n",
    "# EMBEDDING_DIM = num_features\n",
    "# max_length = max([len(s) for s in X])\n",
    "# # maximum length of a number of ingredients\n",
    "\n",
    "# tokenizer_obj = Tokenizer()\n",
    "# tokenizer_obj.fit_on_texts(X)\n",
    "\n",
    "# X_token = tokenizer_obj.texts_to_sequences(X)\n",
    "# X_pad = pad_sequences(X_token, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_index = {}\n",
    "# f = open(os.path.join('','song_tile_embedding.txt'), encoding = 'utf-8')\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:])\n",
    "#     embeddings_index[word] = coefs\n",
    "    \n",
    "# f.close()\n",
    "\n",
    "# word_index = tokenizer_obj.word_index\n",
    "# num_words = len(word_index) + 1\n",
    "\n",
    "# embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         # words not found in embedding index will be all-zeros.\n",
    "#         embedding_matrix[i] = embedding_vector[-EMBEDDING_DIM:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_wv_seq.save_weights('model_wv_seq.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1d66dca1508>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_wv_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_title = 'Saragi Asille'\n",
    "# new_sentences = []\n",
    "# new_sentences.append(new_title.split())\n",
    "# new_sentences\n",
    "# # print(new_title.split())\n",
    "# # new_name_clean = [re.sub(r'[^\\w]', ' ', str(item))for item in new_title]\n",
    "# # new_name_clean = [re.sub(r\" \\d+\", '', str(item.strip())) for item in new_name_clean]\n",
    "# # new_sentences = list()\n",
    "# # for item in new_name_clean:\n",
    "# #     new_sentences.append(item.split())\n",
    "# # new_name_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_token = tokenizer_obj.texts_to_sequences(new_sentences)\n",
    "# X_pad_new = pad_sequences(X_token, maxlen = max_length, padding = 'post')\n",
    "# Song_vector_new = model_wv_seq.predict(X_pad_new)\n",
    "\n",
    "# Song_vector_copy = Song_vector_new.copy()\n",
    "# Song_vector_copy[Song_vector_copy == 0] = np.nan\n",
    "# means_new_song = np.nanmean(Song_vector_copy, axis=1) # the first axis of mean is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.nonzero(Song_vector_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song_vector = model_wv_seq.predict(X_pad[0:16,:],  batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song_vector_copy = Song_vector.copy()\n",
    "# Song_vector_copy[Song_vector_copy == 0] = np.nan\n",
    "# means = np.nanmean(Song_vector_copy, axis=1) # the first axis of mean is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cosine_similarity(means[0].reshape(1, -1), means[2].reshape(1, -1))\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
