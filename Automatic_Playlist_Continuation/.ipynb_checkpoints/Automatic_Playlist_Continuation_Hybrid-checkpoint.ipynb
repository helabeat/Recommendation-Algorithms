{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import gensim \n",
    "from gensim.models import FastText\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Word2vec import make_suggestion\n",
    "from playlists_artists import get_similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.read_csv('../Datasets/Copy of explicit_data - Playlist_data.csv')\n",
    "user_playlist_data = pd.read_csv('../Datasets/Copy of explicit_data - User_playlists.csv')\n",
    "songs = pd.read_csv('../Datasets/Copy of explicit_data - Songs - All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>Top Sinhala Hits</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>New Sinhala songs</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>Sinhala Rap Collection</td>\n",
       "      <td>10019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>Christmas Songs Collection</td>\n",
       "      <td>10022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>Mother's Songs</td>\n",
       "      <td>10065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id               playlist_name  user_id\n",
       "0          101            Top Sinhala Hits    10001\n",
       "1          102           New Sinhala songs    10004\n",
       "2          103      Sinhala Rap Collection    10019\n",
       "3          104  Christmas Songs Collection    10022\n",
       "4          105              Mother's Songs    10065"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>order</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1.396767e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1.396767e+09</td>\n",
       "      <td>26</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>1.396767e+09</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>1.396767e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>1.396767e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  timestamp         order  song_id            \n",
       "0          101      1.396767e+09     25                  312\n",
       "1          101      1.396767e+09     26                  313\n",
       "2          101      1.396767e+09     24                  314\n",
       "3          101      1.396767e+09     23                  315\n",
       "4          101      1.396767e+09     22                  316"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_playlist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Artist_id</th>\n",
       "      <th>Album</th>\n",
       "      <th>Release Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Aa Ra Sulan</td>\n",
       "      <td>Nirosha Virajini</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Aa Ra Sulan</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>Aale katha</td>\n",
       "      <td>Kalpana Nayanamadu, Shermaine Willis ft Iraj</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Aale Katha</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Ada Nam Ma Hada Iwasum Na</td>\n",
       "      <td>Raveen Kanishka &amp; Kalpana Kavindi</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Ada Thaniyen Ma Hadanne Na Ma</td>\n",
       "      <td>Shihan Mihiranga</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Adambarai Baluwama Nam</td>\n",
       "      <td>Surani De Mel</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                          Title  \\\n",
       "0        2                    Aa Ra Sulan   \n",
       "1      283                     Aale katha   \n",
       "2        3      Ada Nam Ma Hada Iwasum Na   \n",
       "3        4  Ada Thaniyen Ma Hadanne Na Ma   \n",
       "4        5         Adambarai Baluwama Nam   \n",
       "\n",
       "                                         Artist  Artist_id        Album  \\\n",
       "0                              Nirosha Virajini       21.0  Aa Ra Sulan   \n",
       "1  Kalpana Nayanamadu, Shermaine Willis ft Iraj       11.0   Aale Katha   \n",
       "2             Raveen Kanishka & Kalpana Kavindi      101.0          NaN   \n",
       "3                              Shihan Mihiranga       62.0          NaN   \n",
       "4                                 Surani De Mel       80.0          NaN   \n",
       "\n",
       "   Release Year  \n",
       "0        2011.0  \n",
       "1        2018.0  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlist_data.columns = ['playlist_id','timestamp','order','song_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Automatic_Playlist_Continuation:\n",
    "    def __init__(self):\n",
    "        self.merged_data = None\n",
    "        \n",
    "    def merge_data(self, user_playlist_data, songs):\n",
    "        self.merged_data = pd.merge(user_playlist_data, songs.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")\n",
    "        self.merged_data['ratings'] = np.ones((self.merged_data.shape[0],), dtype=int)\n",
    "        return self.merged_data\n",
    "    \n",
    "    def get_playlist_name(self, playlist_id, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        playlist_name = df_merge.loc[df_merge['playlist_id']==playlist_id]\n",
    "        return playlist_name\n",
    "\n",
    "    def playlist_songs_matrix(self, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        playlist_songs_matrix = df_merge.pivot(\n",
    "                index='playlist_id',\n",
    "                columns='song_id',\n",
    "                values='ratings'\n",
    "            ).fillna(0)\n",
    "        return playlist_songs_matrix\n",
    "    \n",
    "    def SVD(self, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        ps_matrix = self.playlist_songs_matrix(user_playlist_data, songs)\n",
    "        X = ps_matrix.values.T\n",
    "        SVD = TruncatedSVD(n_components=6, random_state=0)\n",
    "        matrix = SVD.fit_transform(X)\n",
    "        return matrix\n",
    "    \n",
    "    def corelations_between_songs(self, playlist_id, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        playlist_details = self.get_playlist_name(playlist_id, user_playlist_data, songs)\n",
    "        seed_tracks = playlist_details.song_id.values\n",
    "        matrix = SVD(df_merge)\n",
    "        corr = np.corrcoef(matrix)\n",
    "\n",
    "        ps_matrix = self.playlist_songs_matrix(user_playlist_data, songs)\n",
    "        song_ids= ps_matrix.columns\n",
    "        Song_id_list = list(song_ids)\n",
    "        suggestions = []\n",
    "        uniques = []\n",
    "        for i in range(len(seed_tracks)):\n",
    "            track_rating = title_list.index(seed_tracks[i])\n",
    "            corr_samia  = corr[track_rating]\n",
    "            suggestions.append(song_ids[(corr_samia >= 0.5)])\n",
    "        for i in range(len(suggestions)):\n",
    "            for j in suggestions[i]:\n",
    "                uniques.append(j)\n",
    "        uniques = list(dict.fromkeys(uniques))\n",
    "        return uniques  \n",
    "    \n",
    "    def Naive_based_search(self, pat, txt): \n",
    "        M = len(pat) \n",
    "        N = len(txt) \n",
    "\n",
    "        # A loop to slide pat[] one by one */ \n",
    "        for i in range(N - M + 1): \n",
    "            j = 0        \n",
    "            # For current index i, check  \n",
    "            # for pattern match */ \n",
    "            while(j < M): \n",
    "                if (txt[i + j] != pat[j]): \n",
    "                    break\n",
    "                j += 1\n",
    "\n",
    "            if (j == M):  \n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    " \n",
    "    def word_extraction(self, sentence):       \n",
    "        words = re.sub(\"[^\\w]\", \" \",  sentence).split()    \n",
    "        cleaned_text = [w for w in words]    \n",
    "        return cleaned_text\n",
    "\n",
    "    def tokenize(self, sentences):   \n",
    "        words = []    \n",
    "        for sentence in sentences:        \n",
    "            w = self.word_extraction(sentence)        \n",
    "            words.extend(w)            \n",
    "            words = sorted(list(set(words)))    \n",
    "            return words\n",
    "\n",
    "    def generate_bow(self, allsentences):        \n",
    "        vocab = self.tokenize(allsentences)    \n",
    "        # print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "        vector_array = []\n",
    "        for sentence in allsentences:        \n",
    "            words = self.word_extraction(sentence)        \n",
    "            bag_vector = np.zeros(len(vocab))        \n",
    "            for w in words:            \n",
    "                for i,word in enumerate(vocab):                \n",
    "                    if word == w:                     \n",
    "                        bag_vector[i] += 1                            \n",
    "    #         print(\"{0}\\n{1}\\n\".format(sentence,np.array(bag_vector)))\n",
    "            vector_array.append(np.array(bag_vector))\n",
    "        return vector_array\n",
    "\n",
    "    def cosine_similarity_calculator(self, sentence1, sentence2):\n",
    "        allsentences = [sentence1, sentence2]\n",
    "        vocab = self.tokenize(allsentences)\n",
    "        array = self.generate_bow(allsentences)\n",
    "\n",
    "        feature_vec1 = array[0]\n",
    "        feature_vec2 = array[1]\n",
    "\n",
    "        c = 0\n",
    "\n",
    "        for i in range(len(vocab)): \n",
    "            c+= feature_vec1[i]*feature_vec2[i] \n",
    "        cosine = c / float((sum(feature_vec1)*sum(feature_vec2))**0.5) \n",
    "        return cosine \n",
    "    \n",
    "    def string_matching(self, playlist_id, playlists, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        playlist_name = playlists['playlist_name'].loc[playlists['playlist_id'] == playlist_id]\n",
    "        playlist_name = [name for name in playlist_name]\n",
    "    #     print(playlist_name)\n",
    "        words = playlist_name[0].split()\n",
    "        # wighted_word = words[0]\n",
    "        # print(playlists.playlist_name.values)\n",
    "        suggestions = []\n",
    "        for playlist in playlists.playlist_name.values:\n",
    "            for i in words:\n",
    "                if ( self.Naive_based_search(i, playlist) and self.cosine_similarity_calculator(playlist_name[0], playlist) > 0.5):\n",
    "                    playlist_id = playlists['playlist_id'].loc[playlists['playlist_name'] == playlist]\n",
    "                    for i in playlist_id:\n",
    "                        songs = df_merge['song_id'].loc[df_merge['playlist_id'] == i]\n",
    "                        for i in songs:\n",
    "                            suggestions.append(i)\n",
    "                continue\n",
    "        suggestions = list(dict.fromkeys(suggestions))\n",
    "        return suggestions \n",
    "    \n",
    "    def tokenize_sentences(self, list_):\n",
    "        tokens = []\n",
    "        for i in list_:\n",
    "            w = self.word_extraction(i)\n",
    "            tokens.extend(w)\n",
    "            tokens = sorted(list(tokens))\n",
    "        return tokens\n",
    "    \n",
    "    def frequnt_artists_in_playlist(self, playlist_id, playlists, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        platlist_details = self.get_playlist_name(playlist_id, user_playlist_data, songs)\n",
    "        playlist_artist_list = platlist_details.Artist.values\n",
    "        tokens = tokenize_sentences(playlist_artist_list)\n",
    "        \n",
    "        wordfreq = [tokens.count(w) for w in tokens]\n",
    "        return wordfreq    \n",
    "        \n",
    "    def check_for_seed_tracks(self, playlist_id, playlists, user_playlist_data, songs):\n",
    "        df_merge = self.merge_data(user_playlist_data, songs)\n",
    "        no_seed_tracks = len(df_merge.playlist_id.values)\n",
    "        if (no_seed_tracks >= 1):\n",
    "            cbs = self.corelations_between_songs(playlist_id, user_playlist_data, songs)\n",
    "            return cbs\n",
    "        elif no_seed_tracks == 0:\n",
    "            strmatching = self.string_matching(playlist_id, playlists, user_playlist_data, songs)\n",
    "            return strmatching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-f818cf5dea85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# artists = songs.Artist.values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# apc.tokenize_sentences(artists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mapc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequnt_artists_in_playlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m103\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaylists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_playlist_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msongs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# apc.check_for_seed_tracks(103, playlists, user_playlist_data, songs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-274-45fb811a301b>\u001b[0m in \u001b[0;36mfrequnt_artists_in_playlist\u001b[1;34m(self, playlist_id, playlists, user_playlist_data, songs)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mplatlist_details\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_playlist_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaylist_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_playlist_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msongs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mplaylist_artist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplatlist_details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaylist_artist_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mwordfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenize_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "apc = Automatic_Playlist_Continuation()\n",
    "# artists = songs.Artist.values\n",
    "# apc.tokenize_sentences(artists)\n",
    "apc.frequnt_artists_in_playlist(103, playlists, user_playlist_data, songs)\n",
    "# apc.check_for_seed_tracks(103, playlists, user_playlist_data, songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_songs_matrix(df_merge):\n",
    "    playlist_songs_matrix = df_merge.pivot(\n",
    "            index='playlist_id',\n",
    "            columns='song_id',\n",
    "            values='ratings'\n",
    "        ).fillna(0)\n",
    "    return playlist_songs_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlists with seed tracks, use them to get the corelations using Matrix factorization\n",
    "def corelations_between_songs(playlist_id, df_merge):\n",
    "    playlist_details = get_playlist_name(playlist_id, df_merge)\n",
    "    seed_tracks = playlist_details.song_id.values\n",
    "    matrix = SVD(df_merge)\n",
    "    corr = np.corrcoef(matrix)\n",
    "    \n",
    "    ps_matrix = playlist_songs_matrix(df_merge)\n",
    "    song_ids= ps_matrix.columns\n",
    "    Song_id_list = list(song_ids)\n",
    "    suggestions = []\n",
    "    uniques = []\n",
    "    for i in range(len(seed_tracks)):\n",
    "        track_rating = title_list.index(seed_tracks[i])\n",
    "        corr_samia  = corr[track_rating]\n",
    "        suggestions.append(song_ids[(corr_samia >= 0.5)])\n",
    "    for i in range(len(suggestions)):\n",
    "        for j in suggestions[i]:\n",
    "            uniques.append(j)\n",
    "    uniques = list(dict.fromkeys(uniques))\n",
    "    return uniques   \n",
    "\n",
    "def SVD(df_merge):\n",
    "    ps_matrix = playlist_songs_matrix(df_merge)\n",
    "    X = ps_matrix.values.T\n",
    "    SVD = TruncatedSVD(n_components=6, random_state=0)\n",
    "    matrix = SVD.fit_transform(X)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 27, 67, 68, 97, 129, 141, 148, 235]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corelations_between_songs(103, df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([322, 323, 324, 325, 326, 327], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playlist_details = get_playlist_name(104, df_merge)\n",
    "# seed_tracks = playlist_details.song_id.values\n",
    "# seed_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = SVD(df_merge)\n",
    "# corr = np.corrcoef(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[322, 323, 324, 325, 326, 327, 328, 329, 330]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ps_matrix = playlist_songs_matrix(df_merge)\n",
    "# song_ids= ps_matrix.columns\n",
    "# title_list = list(song_ids)\n",
    "# samia = title_list.index(323)\n",
    "# corr_samia  = corr[samia]\n",
    "# list(song_ids[(corr_samia >= 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324, 322, 327, 326, 325, 323]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corelations_between_songs(104, df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token-based string matching palylists with no songs\n",
    "def string_matching(playlist_id, playlists, df_merge):\n",
    "    playlist_name = playlists['playlist_name'].loc[playlists['playlist_id'] == playlist_id]\n",
    "    playlist_name = [name for name in playlist_name]\n",
    "#     print(playlist_name)\n",
    "    words = playlist_name[0].split()\n",
    "    # wighted_word = words[0]\n",
    "    # print(playlists.playlist_name.values)\n",
    "    suggestions = []\n",
    "    for playlist in playlists.playlist_name.values:\n",
    "        for i in words:\n",
    "            if ( Naive_based_search(i, playlist) and cosine_similarity_(playlist_name[0], playlist) > 0.5):\n",
    "                playlist_id = playlists['playlist_id'].loc[playlists['playlist_name'] == playlist]\n",
    "                for i in playlist_id:\n",
    "                    songs = df_merge['song_id'].loc[df_merge['playlist_id'] == i]\n",
    "                    for i in songs:\n",
    "                        suggestions.append(i)\n",
    "            continue\n",
    "    suggestions = list(dict.fromkeys(suggestions))\n",
    "    return suggestions   \n",
    "        \n",
    "def Naive_based_search(pat, txt): \n",
    "    M = len(pat) \n",
    "    N = len(txt) \n",
    "  \n",
    "    # A loop to slide pat[] one by one */ \n",
    "    for i in range(N - M + 1): \n",
    "        j = 0        \n",
    "        # For current index i, check  \n",
    "        # for pattern match */ \n",
    "        while(j < M): \n",
    "            if (txt[i + j] != pat[j]): \n",
    "                break\n",
    "            j += 1\n",
    "  \n",
    "        if (j == M):  \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    " \n",
    "def word_extraction(sentence):       \n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()    \n",
    "    cleaned_text = [w.lower() for w in words]    \n",
    "    return cleaned_text\n",
    "\n",
    "def tokenize(sentences):   \n",
    "    words = []    \n",
    "    for sentence in sentences:        \n",
    "        w = word_extraction(sentence)        \n",
    "        words.extend(w)            \n",
    "        words = sorted(list(set(words)))    \n",
    "        return words\n",
    "\n",
    "def generate_bow(allsentences):        \n",
    "    vocab = tokenize(allsentences)    \n",
    "    # print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "    vector_array = []\n",
    "    for sentence in allsentences:        \n",
    "        words = word_extraction(sentence)        \n",
    "        bag_vector = np.zeros(len(vocab))        \n",
    "        for w in words:            \n",
    "            for i,word in enumerate(vocab):                \n",
    "                if word == w:                     \n",
    "                    bag_vector[i] += 1                            \n",
    "#         print(\"{0}\\n{1}\\n\".format(sentence,np.array(bag_vector)))\n",
    "        vector_array.append(np.array(bag_vector))\n",
    "    return vector_array\n",
    "\n",
    "def cosine_similarity_(sentence1, sentence2):\n",
    "    allsentences = [sentence1, sentence2]\n",
    "    vocab = tokenize(allsentences)\n",
    "    array = generate_bow(allsentences)\n",
    "    \n",
    "    feature_vec1 = array[0]\n",
    "    feature_vec2 = array[1]\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    for i in range(len(vocab)): \n",
    "        c+= feature_vec1[i]*feature_vec2[i] \n",
    "    cosine = c / float((sum(feature_vec1)*sum(feature_vec2))**0.5) \n",
    "    return cosine     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[322, 323, 324, 325, 326, 327, 328, 329, 330]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_matching(104, playlists, df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_seed_tracks(playlist_id, playlists, df_merge):\n",
    "    no_seed_tracks = len(df_merge.playlist_id.values)\n",
    "    if no_seed_tracks >= 1:\n",
    "        cbs = corelations_between_songs(playlist_id, df_merge)\n",
    "        return cbs\n",
    "    elif no_seed_tracks == 0:\n",
    "        strmatching = string_matching(playlist_id, playlists, df_merge)\n",
    "        return strmatching        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between 2 strings is : 0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "# from difflib import SequenceMatcher \n",
    "\n",
    "# def similar(str1, str2): \n",
    "#     return SequenceMatcher(None, str1, str2).ratio() \n",
    "  \n",
    "# # Initializing strings \n",
    "# test_string1 = 'Christmas Songs Collection'\n",
    "# test_string2 = 'Iraj Songs Collection '\n",
    "  \n",
    "# # using SequenceMatcher.ratio() \n",
    "# # similarity between strings \n",
    "# res = similar(test_string1, test_string2) \n",
    "  \n",
    "# # printing the result \n",
    "# print (\"The similarity between 2 strings is : \" + str(res)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>order</th>\n",
       "      <th>song_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Artist_id</th>\n",
       "      <th>Album</th>\n",
       "      <th>Release Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>1.396801e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>Adara Mage Jesuni</td>\n",
       "      <td>Rookantha Gunathilaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>104</td>\n",
       "      <td>1.396801e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>323</td>\n",
       "      <td>Ahas Gabe Sura Duwak</td>\n",
       "      <td>Roshan Ranawana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>104</td>\n",
       "      <td>1.396801e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>324</td>\n",
       "      <td>Ahas Thale Nagei Ruwan</td>\n",
       "      <td>Seetha Nanayakkara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>104</td>\n",
       "      <td>1.396801e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>325</td>\n",
       "      <td>Bethleheme Ada Ra Upanna</td>\n",
       "      <td>Ivo Dennis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>104</td>\n",
       "      <td>1.396801e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>326</td>\n",
       "      <td>Hari Asai Man Jesu Amme</td>\n",
       "      <td>Chandani Hettiarachchi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    playlist_id     timestamp  order  song_id                     Title  \\\n",
       "52          104  1.396801e+09      1      322         Adara Mage Jesuni   \n",
       "53          104  1.396801e+09      2      323      Ahas Gabe Sura Duwak   \n",
       "54          104  1.396801e+09      3      324    Ahas Thale Nagei Ruwan   \n",
       "55          104  1.396801e+09      4      325  Bethleheme Ada Ra Upanna   \n",
       "56          104  1.396801e+09      5      326   Hari Asai Man Jesu Amme   \n",
       "\n",
       "                    Artist  Artist_id Album  Release Year  \n",
       "52   Rookantha Gunathilaka        NaN   NaN           NaN  \n",
       "53         Roshan Ranawana        NaN   NaN           NaN  \n",
       "54      Seetha Nanayakkara        NaN   NaN           NaN  \n",
       "55              Ivo Dennis        NaN   NaN           NaN  \n",
       "56  Chandani Hettiarachchi        NaN   NaN           NaN  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "christmashits = df_merge.loc[df_merge['playlist_id']==104]\n",
    "christmashits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['Adara', 'Mage', 'Jesuni']) list(['Ahas', 'Gabe', 'Sura', 'Duwak'])\n",
      " list(['Ahas', 'Thale', 'Nagei', 'Ruwan'])\n",
      " list(['Bethleheme', 'Ada', 'Ra', 'Upanna'])\n",
      " list(['Hari', 'Asai', 'Man', 'Jesu', 'Amme'])\n",
      " list(['Jesu', 'Bilinda', 'Pabalu', 'Mitaka', 'Pabalu', 'Potaka'])]\n"
     ]
    }
   ],
   "source": [
    "song_name = christmashits.Title.values\n",
    "song_name_clean = [re.sub(r'[^\\w]', ' ', str(item))for item in song_name]\n",
    "song_name_clean = [re.sub(r\" \\d+\", '', str(item.strip())) for item in song_name_clean]\n",
    "sentences = list()\n",
    "for item in song_name_clean:\n",
    "    sentences.append(item.split())\n",
    "unique_sentence = np.unique(sentences)\n",
    "print(unique_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adara',\n",
       " 'Mage',\n",
       " 'Jesuni',\n",
       " 'Ahas',\n",
       " 'Gabe',\n",
       " 'Sura',\n",
       " 'Duwak',\n",
       " 'Ahas',\n",
       " 'Thale',\n",
       " 'Nagei',\n",
       " 'Ruwan',\n",
       " 'Bethleheme',\n",
       " 'Ada',\n",
       " 'Ra',\n",
       " 'Upanna',\n",
       " 'Hari',\n",
       " 'Asai',\n",
       " 'Man',\n",
       " 'Jesu',\n",
       " 'Amme',\n",
       " 'Jesu',\n",
       " 'Bilinda',\n",
       " 'Pabalu',\n",
       " 'Mitaka',\n",
       " 'Pabalu',\n",
       " 'Potaka']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof = []\n",
    "for i in range (len(unique_sentence)):\n",
    "    for j in range (len(unique_sentence[i])):\n",
    "        bof.append(unique_sentence[i][j])\n",
    "bof\n",
    "#     print(unique_sentence[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(workers=1, \\\n",
    "            size=50, min_count = 1, \\\n",
    "            window = 3, sample = 1e-3, sg = 1)\n",
    "model.build_vocab(sentences = unique_sentence)\n",
    "model.train(sentences = unique_sentence,  total_examples=len(sentences), epochs=10)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentence_vector(song_id, model, num_features, bof):\n",
    "    #function to average all words vectors in a given paragraph\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    song = songs['Title'].loc[songs['song_id'] == song_id]\n",
    "    for i in song:\n",
    "        words = i.split()\n",
    "    for word in words:\n",
    "        if word in bof:\n",
    "            nwords = nwords+1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "    if nwords>0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "sentence_1_avg_vector = avg_sentence_vector(326, model, 50, bof)\n",
    "sentence_2_avg_vector = avg_sentence_vector(322, model, 50, bof)\n",
    "\n",
    "sen1_sen2_similarity =  cosine_similarity(sentence_1_avg_vector.reshape(1, -1),sentence_2_avg_vector.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25944144]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1_sen2_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = []\n",
    "for i in sen1_sen2_similarity:\n",
    "    if i >0:\n",
    "        suggestion.append(326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[326]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.17404573, -0.08310194, -0.15794115,  0.04011351, -0.18104142,\n",
       "       -0.2023017 ,  0.15160263,  0.16216323, -0.25352368,  0.13920687,\n",
       "       -0.06056456, -0.13932937,  0.19024621,  0.02643881, -0.03822826,\n",
       "        0.03730683, -0.02529872,  0.10398544, -0.25690755,  0.14317258,\n",
       "        0.21698433, -0.11592035,  0.17221488,  0.2573282 ,  0.07583775,\n",
       "       -0.02905918, -0.22023591,  0.09582233, -0.13842624,  0.15990545,\n",
       "        0.07964834,  0.05270344,  0.17850854,  0.21490698, -0.10688012,\n",
       "        0.09963941, -0.19339395, -0.03871592,  0.21963869, -0.0247773 ,\n",
       "        0.01091725, -0.04160064, -0.05900051,  0.11428913, -0.03796794,\n",
       "       -0.17467375,  0.10172103, -0.15207782, -0.11435612,  0.10123568],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureVec = np.zeros((50,), dtype=\"float32\")\n",
    "nwords = 0\n",
    "words = 'Jesu Jesu Oba Innawa'\n",
    "for word in words.split():\n",
    "    if word in bof:\n",
    "            nwords = nwords+1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "if nwords>0:\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.05801524, -0.02770065, -0.05264705,  0.01337117, -0.06034714,\n",
       "       -0.0674339 ,  0.05053421,  0.05405441, -0.08450789,  0.04640229,\n",
       "       -0.02018819, -0.04644312,  0.0634154 ,  0.00881294, -0.01274275,\n",
       "        0.01243561, -0.00843291,  0.03466181, -0.08563585,  0.04772419,\n",
       "        0.07232811, -0.03864012,  0.05740496,  0.08577607,  0.02527925,\n",
       "       -0.00968639, -0.07341197,  0.03194078, -0.04614208,  0.05330181,\n",
       "        0.02654945,  0.01756782,  0.05950284,  0.07163566, -0.03562671,\n",
       "        0.03321313, -0.06446465, -0.01290531,  0.0732129 , -0.0082591 ,\n",
       "        0.00363908, -0.01386688, -0.01966684,  0.03809638, -0.01265598,\n",
       "       -0.05822458,  0.03390701, -0.05069261, -0.03811871,  0.03374523],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureVec2 = np.zeros((50,), dtype=\"float32\")\n",
    "nwords = 0\n",
    "words = 'Adara Mage Jesuni'\n",
    "for word in words.split():\n",
    "    if word in bof:\n",
    "            nwords = nwords+1\n",
    "            featureVec2 = np.add(featureVec2, model[word])\n",
    "if nwords>0:\n",
    "    featureVec2 = np.divide(featureVec, nwords)\n",
    "featureVec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureVec3 = np.zeros((50,), dtype=\"float32\")\n",
    "nwords = 0\n",
    "words = 'Kithu Saminde'\n",
    "for word in words.split():\n",
    "    if word in bof:\n",
    "            nwords = nwords+1\n",
    "            featureVec2 = np.add(featureVec2, model[word])\n",
    "if nwords>0:\n",
    "    featureVec3 = np.divide(featureVec, nwords)\n",
    "featureVec3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureVec = np.array(featureVec)\n",
    "# featureVec.shape\n",
    "# featureVec2 = np.array(featureVec2)\n",
    "# print(cosine_similarity(featureVec.reshape(-1, 1), featureVec2.reshape(-1, 1)))\n",
    "sen1_sen2_similarity =  cosine_similarity(featureVec3.reshape(1, -1),featureVec2.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1_sen2_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentence_vector(words, model, num_features, index2word_set):\n",
    "    #function to average all words vectors in a given paragraph\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in bof:\n",
    "            nwords = nwords+1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "    if nwords>0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 50    # Word vector dimensionality                      \n",
    "min_word_count = 1                      \n",
    "num_workers = 1      # Number of CPUs\n",
    "context = 3          # Context window size; \n",
    "\n",
    "downsampling = 1e-3   # threshold for configuring which \n",
    "                              # higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model = FastText(unique_sentence, min_count=1,size= 50,workers=3, window =3, sg = 1)\n",
    "# model = Word2Vec(workers=num_workers, \\\n",
    "#             size=num_features, min_count = min_word_count, \\\n",
    "#             window = context, sample = downsampling, sg = 1)\n",
    "\n",
    "\n",
    "# model.build_vocab(sentences = unique_sentence)\n",
    "# model.train(sentences = unique_sentence,  total_examples=len(sentences), epochs=10)\n",
    "# model.init_sims(replace=True)\n",
    "# model.save('Fasttext_playlist.model')\n",
    "\n",
    "# model = FastText.load('Fasttext_playlist.model')\n",
    "\n",
    "# # split the song title\n",
    "# music = songs\n",
    "# song_titles = music.Titles.values\n",
    "\n",
    "# tokens = song_name.split() \n",
    "        \n",
    "# suggestions = []\n",
    "\n",
    "#         # check for most similar items form the model\n",
    "#         suggestions.append(model.wv.most_similar(positive=tokens, topn=10))\n",
    "\n",
    "#         predictions = []\n",
    "#         for l in range(len(suggestions[0])):\n",
    "#             for i in range(len(unique_sentence)):\n",
    "#                 for j in range(len(unique_sentence[i])):\n",
    "#                     if unique_sentence[i][j] == suggestions[0][l][0]:\n",
    "# #                         print(unique_sentence[i])\n",
    "#                         s = ' '\n",
    "#                         word = s.join(unique_sentence[i])\n",
    "# #                         print(word)\n",
    "#                         predictions.append(word)\n",
    "\n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Jesuni', 0.3984375),\n",
       " ('Mage', 0.22209984064102173),\n",
       " ('Upanna', 0.1727343201637268),\n",
       " ('Adara', 0.15519069135189056),\n",
       " ('Nagei', 0.15251873433589935),\n",
       " ('Asai', 0.12244722992181778),\n",
       " ('Ra', 0.12014706432819366),\n",
       " ('Ada', 0.11284378916025162),\n",
       " ('Sura', 0.11033094674348831),\n",
       " ('Pabalu', 0.05470521003007889)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Jesu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aa Ra Sulan', 'Aale katha', 'Ada Nam Ma Hada Iwasum Na',\n",
       "       'Ada Thaniyen Ma Hadanne Na Ma', 'Adambarai Baluwama Nam',\n",
       "       'Adanne Ay Sudu Manike', 'Adaraneeya Neranjana ', 'Adaraya Ayai',\n",
       "       'Adare sithum', 'Adarema Geethayak', 'Adaren (Lanwenna Hithuwata)',\n",
       "       'Aduru kutiya thula ', 'Ae', 'Ahasin eha', 'Ahasin polowata',\n",
       "       'Ai Kale Adare', 'Ai kale mulu hadinma', 'Akeekaru pem kathawak',\n",
       "       'Alawanthakam', 'Alen Ma', 'Alen Wela Ganna', 'Amma Sandaki',\n",
       "       'Anagathaye', 'Ananthayata Yana Para Dige', 'Ananthaye ',\n",
       "       'Anatha maruthe ', 'Api hagum walata ida dee mohothak',\n",
       "       'Api kauruda', 'Arabumama Kadulak Wela Ma Bala Iddi',\n",
       "       'Atha Kadukara Himau Arane',\n",
       "       'Atha Ran Wiman Thulin Pata Selayen Sadi', 'Athinwath atha',\n",
       "       'Athithaya Sihinayak Pamanai', 'Athsana',\n",
       "       'Awado Sansare Ma Ha Badee', 'Awathan hade',\n",
       "       'Ay Kale Mulu Hadinma Oba Mata Adare', 'Ayage Sinaha',\n",
       "       'Baila Gamuda', 'Billa', ' Sina Podak Wee', 'Chain', 'Chakithaya',\n",
       "       'Chandani Payala', 'Chandrayan Pidu Kiranak Sagawala Horen',\n",
       "       'Channa Kinnaravi', 'Ciao Malli', 'Cuore Nero (Italian)',\n",
       "       'Daasin Paa', 'Daffodil mala', 'Daiwaye Saradamin',\n",
       "       'Das Piyan Wesena Asille', 'Dasama riddana',\n",
       "       'Dasin Pa Ma Ingi Maru Dewliye', 'Dedunna Sedi', 'Denuwan piya',\n",
       "       'Dewadaththa', 'Dewagana', 'Dewiyo Wadee', 'Dinuma Paraduma',\n",
       "       'Diwasaravi', 'Duka Danna Nisai Mulu Hadinma',\n",
       "       'Duwe Nuba Mage Pranayai', 'Eka wasanthayaka', 'Eka yaye',\n",
       "       'Esdeka Pura-Yannam Yannam', 'Etha kandukara', 'Eya Meya',\n",
       "       'Galana ganga', 'Gamata Kalin Hiru', 'Gamen Liyumak Awilla',\n",
       "       'Gassana Dagha Malla', 'Gayamu dawasaka', 'Golu Daruwek Una Kiya',\n",
       "       'Gomara mala', 'Gum Nade', 'Hama deyak pene', 'Hanguman',\n",
       "       'Hanthana Sihine(Bala Walapemi)', 'Hanthanata Payana Sanda',\n",
       "       'Hawasaka Ma', 'Heena Maka', 'Hethuwa', 'Hey Kakulee', 'Hiinamaka',\n",
       "       'Hinahenne Mung Mey Wil Theeraye', 'Hini peththta', 'Hiru Mal',\n",
       "       'Hitha Assata', 'Hitha Dura Handa', 'Hitha Hiriwetunado',\n",
       "       'Hitha Mithuru Sulaga ', 'Hitha Nambara Thaleta',\n",
       "       'Hitha Wawannema Na',\n",
       "       'Hithin yana aya athin alla nawathtannata be', 'Husmath unui',\n",
       "       \"I can't Keep Lying\", 'Iduwari', 'Iki Gasa Hadana Atheethayaka',\n",
       "       'Iwasaida Manda', 'Iwasanna Bari Tharam',\n",
       "       'Jeewithaye Sundara Bawa', 'Kaada Raja (Revised Mix)', 'Kaasi',\n",
       "       'Kalakanni loke', 'Kalu Hitha', 'Kamaniya',\n",
       "       'Kampa Nowan Mahamaya(Nissara Wu Sansaraye)', 'Kandulu irthuwe',\n",
       "       'Katawath Ba', 'Kath Kawuruwath Nathi Bawa',\n",
       "       'Kaulu Piyan Path Wahanna', 'Kawada Ho (Laga Nathi Bawa Danenawa',\n",
       "       'Kawikaariye', 'Kawiya Oba', 'Kiri Kodu Hithata',\n",
       "       'Ko ma pathu nube adare', 'Kohe Yannada Ma', 'Kshemaye nagare',\n",
       "       'Kuweni ', 'Labhadiye', 'Landune', 'Lanka Matha',\n",
       "       'Liyathambara Mudu Kusumaki Aae', 'Lokayen Yamu',\n",
       "       'Lu (Numba Nomathi Dihawaka)', 'Ma Hadawala ',\n",
       "       'Ma Oba Hamuwana Dinaye', 'Mage Kiya Eth Wela', 'Mage ne',\n",
       "       'Mage punchi rosa male ', 'Mage sihine obai', 'Mage Unmade',\n",
       "       'Maha Warusawata Pasuwa Nagena Sanda', 'Mahamaaya', 'Mal Madahasa',\n",
       "       'Mal Mitak Thiyanna', 'Mal pan podak', 'Malak Une Ai Numba Mata',\n",
       "       'Malakuth thibuna', 'Ma Adaraneeya Mage Amma Wethatai',\n",
       "       'Mana Bandu', 'Manamali', 'Mandakini', 'Mandaram Wahi Watena',\n",
       "       'Mankiniye', 'Marambari Kola Wee', 'Maraya[2018]', 'Marunu Hithe',\n",
       "       'Master sir   ', 'Mata Rawana', 'Math mage hitha', 'Mathakai Eda',\n",
       "       'Mathakaida ada wage', 'Mathakaya Asurin Sihiyata Gannata',\n",
       "       'Mawena', 'Mayam Kalawe', 'Mayawee', 'Me Avurudu Kale ',\n",
       "       'Me diganthayeee', 'Me Hitha Thaniyen', 'Me mal yaye ',\n",
       "       'Me Sanda Unath Paya Awith', 'Me Tharam Siyumalida Kalugal',\n",
       "       'Meeduma Uthurana', 'Mey Jeewithe', 'Mihiravi ', 'Mihirawa Awa',\n",
       "       'Mumunanawa', 'Muwa muktha latha', 'Na Thawath Hithak',\n",
       "       'Nadagam Geeya', 'Nadee Ganga Tharanaye', 'Nalawena Sulagak',\n",
       "       'Nattami', 'Natuwen Gilihunu Pinna Malak', 'Naukawa',\n",
       "       'Nawathi Methekin', 'Neela Kobei Rana Adii', 'Neela Nimnaye',\n",
       "       'Nethu dahan', 'Nethu Kalma Ma Welai', 'Nethu Saluna', 'Nimnawiye',\n",
       "       'Ninda Noyana Handawe', 'Nirayase',\n",
       "       'Niwaduwatath Man Dan Sankawen', 'Numbada bimba', 'Nura wasanthe',\n",
       "       'Nurawee', 'Oba apple malak wage', 'Oba Dakala',\n",
       "       'Oba Dutu E Mul Dine', 'Oba Enna Aye', 'Oba Ha Mema Athinath Aran',\n",
       "       'Oba Heenayak Wage Hadu Wessak Aran', 'Oba Kamathi Nam',\n",
       "       'Oba Kauda', 'Oba Magemai', 'Oba Nisa', 'Obage Mathaken',\n",
       "       'Oya Magenam', 'Paaren ', 'Pamawee Pipunu Mal Suwandai', 'Pandama',\n",
       "       'Pawena kodu akase', 'Pawena Loke', 'Paya Ena Sanda Watha Manaram',\n",
       "       'Pera Dinayaka Ma Pem Kala Yuwathiya', 'Perada Mawu Sina',\n",
       "       'Perawadanak', 'Pini Binduwak Wennata Asai',\n",
       "       'Pinna Male Suda Anna Gihin Wada', 'Pitasakwala Yaane', 'Piyawuna',\n",
       "       'Prarthanawe', 'Prasiddiya Ko', 'Prathihari', 'Prema sajjayanaya',\n",
       "       'Premaye wil there ', 'Premayen mana ranjitha we', 'Ra ahase',\n",
       "       'Ra Ahasin Wetena Bindu Bindu', 'Ra Pura Payana Tharuka',\n",
       "       'Ra Thisse Awilla', 'Raata man', 'Radhawani', 'Radical paththini',\n",
       "       'Rahase Handana Apa Hagum', 'Rahath himiwaru', 'Rambari',\n",
       "       'Ran Dakaththen', 'Ran Kurahan Mala', 'Ran wan mal dam',\n",
       "       'Rangume ', 'Reta Mang', 'Ridena Noriddena', 'Robarosiyan',\n",
       "       'Rodha Bandila', 'Ron Podak', 'Rosa Kalpna ', 'Ru Sara',\n",
       "       'Runawiye', 'Sada Eliya Gala Ena', 'Sadha Ebennnepa',\n",
       "       'Sadha Oba Mage', 'Sadha Tharu Mal Mata Dan Dun', 'Samawak na',\n",
       "       'Sanda Latha Payala', 'Sanda Nawath Kamak Nathe ',\n",
       "       'Sanda pahan raye', 'Sanda Thaniyama', 'Sandaganawa', 'Sandanari',\n",
       "       'Sandawathiya Obai', 'Sansara Sihine ', 'Sansaraye ma',\n",
       "       'Sara Sadhe', 'Sara Sihina Rahase Diwura Kiya',\n",
       "       'Saragaye (Niya Rata Mawanawa)', 'Saragee Asille', 'Sasthara',\n",
       "       'Sathanta Kiyanna', 'Seetha Maruthe Welemin Es Diha Balan',\n",
       "       'Seethala Heene', 'Senehasakata Aruthak Purawannata', 'Sepalikawo',\n",
       "       'Sharadha', 'Sihina Lowe Maya Wethire', 'Sihinaya', 'Sihine',\n",
       "       'Sikuru Tharuwa Raye', 'Sinasenna', 'Singali None',\n",
       "       'Sinha Lokaye Sinhaya', 'Sithin Ma Noseli', 'Siyumali',\n",
       "       'Sonduru Atheethaye Nimala Pathumawee', 'Sonduru Siththam', 'Soro',\n",
       "       'Soya Awa', 'Sudu Gawma', 'Sulagak Wela Oba Soya Enna One',\n",
       "       'Sulanga Obada', 'Surath Suwaya(Nil Warala Pura)',\n",
       "       'Suwada saban anga gaala', 'Thanhawa Pirila', 'Tharanaya',\n",
       "       'Tharuka Pelin Eha', 'Thawa dawasak', 'Thurul Wenna Asai',\n",
       "       'Tiken Tika Tiken Tika', 'Ulkapathayak', 'Unmada chithra',\n",
       "       'Unmada Wu Premadare ', 'Unmadini Hanguna', 'Unuhuma 2-Aradhana',\n",
       "       'Wakkada Langa(Kaluu)', 'Wala thiryen eha',\n",
       "       'Walithara Athare Himihita Basina',\n",
       "       'Wasanthaye Aga Hamuwemu Sonduriya', 'Wasanthaye Pipidena Mal',\n",
       "       'Wassama', 'Wassanayata Atha Wanala', 'Wikasitha Pem Pokuru Piyum',\n",
       "       'Yaal Panamen', 'Yakkun Pitiyata', 'Walakulaka Kandulu Piruna',\n",
       "       'Umathu Prema Kumara (Chanchala Hagumaka Gilila)',\n",
       "       'Tharu Kada Watunu Dura Akase', 'Siththamai Numba',\n",
       "       'Seetha Ra Weluna Horen', 'Puran Wu Ketha',\n",
       "       'Pamawee Aa Wasanthe (Puran Wu Sitha Sameepe)',\n",
       "       'Kolamba Kirilli (Pana Balum Rangana Rangum)', 'Lassanata Idunu',\n",
       "       'Sudu Amma (Adaraye Mul Akura Wela)', 'Adara Mage Jesuni',\n",
       "       'Ahas Gabe Sura Duwak', 'Ahas Thale Nagei Ruwan',\n",
       "       'Bethleheme Ada Ra Upanna', 'Hari Asai Man Jesu Amme',\n",
       "       'Jesu Bilinda (Pabalu Mitaka Pabalu Potaka)',\n",
       "       'Jesu Jesu Oba Innawa', 'Kithu Saminde',\n",
       "       'Kalakata Pera Ea Bethlehem', 'Amma (Senehasa Aran)',\n",
       "       'Amma (Sansare Patha Aapu)', 'Amma Budu Wewa',\n",
       "       'Amma (Adare Uthura Hinahuna)', 'Adaraye Ulpatha Wu Amma',\n",
       "       'Amma Mathu Buduwana Amma', 'Ammala Duk Ganne', 'Ammawarune'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_titles = songs.Title.values\n",
    "songs_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('Copy of explicit_data - Artists - All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>6th Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>ajith muthukumarana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Amarasiri Peris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>Amasha Tissera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>Amila Nidahasa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id               artist\n",
       "0        123             6th Lane\n",
       "1         63  ajith muthukumarana\n",
       "2          1      Amarasiri Peris\n",
       "3         73       Amasha Tissera\n",
       "4         48       Amila Nidahasa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "playlist_id       int64\n",
       "timestamp       float64\n",
       "order             int64\n",
       "song_id           int64\n",
       "Title            object\n",
       "Artist           object\n",
       "Artist_id       float64\n",
       "Album            object\n",
       "Release Year    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
