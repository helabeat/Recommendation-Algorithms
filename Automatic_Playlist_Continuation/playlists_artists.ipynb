{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import gensim \n",
    "from gensim.models import FastText\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.read_csv('../Datasets/Copy of explicit_data - Playlist_data.csv')\n",
    "user_playlist_data = pd.read_csv('../Datasets/Copy of explicit_data - User_playlists.csv')\n",
    "songs = pd.read_csv('../Datasets/Copy of explicit_data - Songs - All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlist_data.columns = ['playlist_id','timestamp','order','song_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_data(user_playlist_data, songs):\n",
    "    merged_data = pd.merge(user_playlist_data, songs.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")\n",
    "    \n",
    "    merged_data['ratings'] = np.ones((merged_data.shape[0],), dtype=int)\n",
    "    return merged_data\n",
    "    \n",
    "def get_playlist_name(playlist_id):\n",
    "    df_merge = merge_data(user_playlist_data, songs)\n",
    "    playlist_name = df_merge.loc[df_merge['playlist_id']==playlist_id]\n",
    "    return playlist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_playlist_songs_with_artists(playlist_id):\n",
    "    playlist_name = get_playlist_name(playlist_id)\n",
    "    artist_list = playlist_name.Artist.values\n",
    "    similarity, vocab = generate_bow(artist_list)\n",
    "    df=pd.DataFrame(similarity,columns=vocab)\n",
    "    quantity = df.sum(axis = 0)\n",
    "    quantity = pd.DataFrame(quantity)\n",
    "    quantity.reset_index(level=0, inplace=True)\n",
    "    quantity.columns = ['string','frequency']\n",
    "    max_artist = quantity['string'].loc[quantity['frequency'] == max(quantity['frequency']) ]\n",
    "    return [w for w in max_artist]\n",
    "\n",
    "def get_similar_songs(playlist_id, songs):\n",
    "    artist_list = songs.Artist.values\n",
    "    frequent_artist = train_playlist_songs_with_artists(playlist_id)\n",
    "    #print(frequent_artist[0])\n",
    "    uniques = []\n",
    "    for i in artist_list:\n",
    "        #print(i)\n",
    "        if(Naive_based_search(frequent_artist[0], i)):\n",
    "            suggestions = songs['song_id'].loc[songs['Artist'] == i]\n",
    "            #print(suggestions)\n",
    "            for idx in suggestions:\n",
    "                uniques.append(idx)\n",
    "        else:\n",
    "            continue\n",
    "    uniques = list(dict.fromkeys(uniques))\n",
    "    return uniques\n",
    "\n",
    "def Naive_based_search(pat, txt): \n",
    "        M = len(pat) \n",
    "        N = len(txt) \n",
    "\n",
    "        # A loop to slide pat[] one by one */ \n",
    "        for i in range(N - M + 1): \n",
    "            j = 0        \n",
    "            # For current index i, check  \n",
    "            # for pattern match */ \n",
    "            while(j < M): \n",
    "                if (txt[i + j] != pat[j]): \n",
    "                    break\n",
    "                j += 1\n",
    "\n",
    "            if (j == M):  \n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "def word_extraction(sentence):       \n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()    \n",
    "    cleaned_text = [w for w in words]    \n",
    "    return cleaned_text\n",
    "\n",
    "def tokenize(sentences):   \n",
    "    words = []    \n",
    "    for sentence in sentences:        \n",
    "        w = word_extraction(sentence)        \n",
    "        words.extend(w)            \n",
    "        words = sorted(list(set(words)))    \n",
    "        return words\n",
    "\n",
    "def generate_bow(allsentences):        \n",
    "    vocab = tokenize(allsentences)    \n",
    "    # print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "    vector_array = []\n",
    "    for sentence in allsentences:        \n",
    "        words = word_extraction(sentence)        \n",
    "        bag_vector = np.zeros(len(vocab))        \n",
    "        for w in words:            \n",
    "            for i,word in enumerate(vocab):                \n",
    "                if word == w:                     \n",
    "                    bag_vector[i] += 1                            \n",
    "    #         print(\"{0}\\n{1}\\n\".format(sentence,np.array(bag_vector)))\n",
    "        vector_array.append(np.array(bag_vector))\n",
    "    return vector_array, vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 27, 68, 148, 170, 181, 195, 141, 150, 203]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_songs(103, songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
