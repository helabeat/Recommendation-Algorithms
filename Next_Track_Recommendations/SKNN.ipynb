{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\Maneesha\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from _operator import itemgetter\n",
    "from math import sqrt\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "from pympler import asizeof\n",
    "from math import log10\n",
    "import scipy.sparse\n",
    "from scipy.sparse.csc import csc_matrix\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Copy of explicit_data - Session Data - Songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKNN:\n",
    "    def __init__( self, k=100, sample_size=1000, sampling='recent',  similarity = 'cosine', remind=False, pop_boost=0, \n",
    "                 extend=False, normalize=True, session_key = 'SessionId', item_key= 'ItemId', time_key= 'Time' ):\n",
    "        self.remind = remind\n",
    "        self.k = k\n",
    "        self.sample_size = sample_size\n",
    "        self.sampling = sampling\n",
    "        self.similarity = similarity\n",
    "        self.session_key = session_key\n",
    "        self.pop_boost = pop_boost\n",
    "        self.item_key = item_key\n",
    "        self.time_key = time_key\n",
    "        self.extend = extend\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        #updated while recommending\n",
    "        self.session = -1\n",
    "        self.session_items = []\n",
    "        self.relevant_sessions = set()\n",
    "        \n",
    "        # cache relations once at startup\n",
    "        self.session_item_map = dict() \n",
    "        self.item_session_map = dict()\n",
    "        self.session_time = dict()\n",
    "        \n",
    "        self.sim_time = 0\n",
    "        \n",
    "        \n",
    "    # Trains the predictor\n",
    "    # Training data : Session Ids, Item Ids and timestamp\n",
    "    \n",
    "    def train_data(self, train, items=None):\n",
    "        index_session = 0 #train.columns.get_loc( self.session_key )\n",
    "        index_item = 1 #train.columns.get_loc( self.item_key )\n",
    "        index_time = 2 #train.columns.get_loc( self.time_key )\n",
    "            \n",
    "        session = -1\n",
    "        session_items = set()\n",
    "        time = -1\n",
    "        #cnt = 0\n",
    "        for row in train.itertuples(index=False):\n",
    "            # cache items of sessions\n",
    "            if row[index_session] != session:\n",
    "                if len(session_items) > 0:\n",
    "                    self.session_item_map.update({session : session_items})\n",
    "                    # cache the last time stamp of the session\n",
    "                    self.session_time.update({session : time})\n",
    "                session = row[index_session]\n",
    "                session_items = set()\n",
    "            time = row[index_time]\n",
    "            session_items.add(row[index_item])\n",
    "            \n",
    "            # cache sessions involving an item\n",
    "            map_is = self.item_session_map.get( row[index_item] )\n",
    "            if map_is is None:\n",
    "                map_is = set()\n",
    "                self.item_session_map.update({row[index_item] : map_is})\n",
    "            map_is.add(row[index_session])\n",
    "                \n",
    "        # Add the last tuple    \n",
    "        self.session_item_map.update({session : session_items})\n",
    "        self.session_time.update({session : time})\n",
    "        \n",
    "    # Give prediction scores for a selected set of items on how likely they be the next item in the session\n",
    "    # output : Prediction scores for selected items on how likely to be the next items of the session. Indexed by the item IDs.\n",
    "        \n",
    "    def predict_next( self, session_id, input_item_id, predict_for_item_ids, input_user_id=None, skip=False, type='view', timestamp=0 ):\n",
    "        if( self.session != session_id ): #new session\n",
    "            \n",
    "            if( self.extend ):\n",
    "                item_set = set( self.session_items )\n",
    "                self.session_item_map[self.session] = item_set;\n",
    "                for item in item_set:\n",
    "                    map_is = self.item_session_map.get( item )\n",
    "                    if map_is is None:\n",
    "                        map_is = set()\n",
    "                        self.item_session_map.update({item : map_is})\n",
    "                    map_is.add(self.session)\n",
    "                    \n",
    "                ts = time.time()\n",
    "                self.session_time.update({self.session : ts})\n",
    "                \n",
    "                \n",
    "            self.session = session_id\n",
    "            self.session_items = list()\n",
    "            self.relevant_sessions = set()\n",
    "            \n",
    "        if type == 'view':\n",
    "            self.session_items.append( input_item_id )\n",
    "        \n",
    "        if skip:\n",
    "            return\n",
    "                        \n",
    "        neighbors = self.find_neighbors( set(self.session_items), input_item_id, session_id )\n",
    "        scores = self.score_items( neighbors )\n",
    "        \n",
    "        # add some reminders\n",
    "        if self.remind:\n",
    "             \n",
    "            reminderScore = 5\n",
    "            takeLastN = 3\n",
    "             \n",
    "            cnt = 0\n",
    "            for elem in self.session_items[-takeLastN:]:\n",
    "                cnt = cnt + 1\n",
    "                #reminderScore = reminderScore + (cnt/100)\n",
    "                 \n",
    "                oldScore = scores.get( elem )\n",
    "                newScore = 0\n",
    "                if oldScore is None:\n",
    "                    newScore = reminderScore\n",
    "                else:\n",
    "                    newScore = oldScore + reminderScore\n",
    "                #print 'old score ', oldScore\n",
    "                # update the score and add a small number for the position \n",
    "                newScore = (newScore * reminderScore) + (cnt/100)\n",
    "                 \n",
    "                scores.update({elem : newScore})\n",
    "                \n",
    "        #push popular ones\n",
    "        if self.pop_boost > 0:\n",
    "               \n",
    "            pop = self.item_popularity( neighbors )\n",
    "            # Iterate over the item neighbors\n",
    "            #print itemScores\n",
    "            for key in scores:\n",
    "                item_pop = pop.get(key)\n",
    "                # Gives some minimal MRR boost?\n",
    "                scores.update({key : (scores[key] + (self.pop_boost * item_pop))})\n",
    "                \n",
    "        # Create things in the format ..\n",
    "        predictions = np.zeros(len(predict_for_item_ids))\n",
    "        mask = np.in1d( predict_for_item_ids, list(scores.keys()) )\n",
    "        predict_for_item_ids = np.array(predict_for_item_ids)\n",
    "        \n",
    "        items = predict_for_item_ids[mask]\n",
    "        values = [scores[x] for x in items]\n",
    "        predictions[mask] = values\n",
    "        series = pd.Series(data=\n",
    "                           predictions, index=predict_for_item_ids)\n",
    "        \n",
    "        if self.normalize:\n",
    "            series = series / series.max()\n",
    "        \n",
    "        return series\n",
    "    \n",
    "    # Give the item popularity for the given list of sessions\n",
    "\n",
    "    \n",
    "    def item_popularity(self, sessions):\n",
    "        result = dict()\n",
    "        max_pop = 0\n",
    "        for session in sessions:\n",
    "            items = self.items_for_session( session )\n",
    "            #print(items)\n",
    "            for item in items:\n",
    "                \n",
    "                #print(item)\n",
    "                \n",
    "                count = result.get(item)\n",
    "                #print(count)\n",
    "                if count is None:\n",
    "                    result.update({item: 1})\n",
    "                else:\n",
    "                    result.update({item: count + 1})\n",
    "                    \n",
    "                if( result.get(item) > max_pop ):\n",
    "                    max_pop =  result.get(item)\n",
    "         \n",
    "        for key in result:\n",
    "            #print(max_pop)\n",
    "            result.update({key: ( result[key] / max_pop )})\n",
    "                   \n",
    "        return result\n",
    "    \n",
    "    def cosine(self, first, second):\n",
    "        li = len(first&second)\n",
    "        la = len(first)\n",
    "        lb = len(second)\n",
    "        result = li / sqrt(la) * sqrt(lb)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def random(self, first, second):\n",
    "        return random.random()\n",
    "    \n",
    "    def items_for_session(self, session):\n",
    "        return self.session_item_map.get(session);\n",
    "    \n",
    "    def sessions_for_item(self, item_id):\n",
    "        return self.item_session_map.get( item_id )\n",
    "    \n",
    "    def most_recent_sessions( self, sessions, number ):\n",
    "        sample = set()\n",
    "\n",
    "        tuples = list()\n",
    "        for session in sessions:\n",
    "            time = self.session_time.get( session )\n",
    "            if time is None:\n",
    "                print(' EMPTY TIMESTAMP!! ', session)\n",
    "            tuples.append((session, time))\n",
    "            \n",
    "        tuples = sorted(tuples, key=itemgetter(1), reverse=True)\n",
    "        #print 'sorted list ', sortedList\n",
    "        cnt = 0\n",
    "        for element in tuples:\n",
    "            cnt = cnt + 1\n",
    "            if cnt > number:\n",
    "                break\n",
    "            sample.add( element[0] )\n",
    "        #print 'returning sample of size ', len(sample)\n",
    "        return sample\n",
    "    \n",
    "    def possible_neighbor_sessions(self, session_items, input_item_id, session_id):\n",
    "        self.relevant_sessions = self.relevant_sessions | self.sessions_for_item( input_item_id );\n",
    "               \n",
    "        if self.sample_size == 0: #use all session as possible neighbors\n",
    "            \n",
    "            print('!!!!! runnig KNN without a sample size (check config)')\n",
    "            return self.relevant_sessions\n",
    "\n",
    "        else: #sample some sessions\n",
    "                \n",
    "            self.relevant_sessions = self.relevant_sessions | self.sessions_for_item( input_item_id );\n",
    "                         \n",
    "            if len(self.relevant_sessions) > self.sample_size:\n",
    "                \n",
    "                if self.sampling == 'recent':\n",
    "                    sample = self.most_recent_sessions( self.relevant_sessions, self.sample_size )\n",
    "                elif self.sampling == 'random':\n",
    "                    sample = random.sample( self.relevant_sessions, self.sample_size )\n",
    "                else:\n",
    "                    sample = self.relevant_sessions[:self.sample_size]\n",
    "                    \n",
    "                return sample\n",
    "            else: \n",
    "                return self.relevant_sessions\n",
    "            \n",
    "    def calc_similarity(self, session_items, sessions ):\n",
    "        neighbors = []\n",
    "        cnt = 0\n",
    "        for session in sessions:\n",
    "            cnt = cnt + 1\n",
    "            # get items of the session, look up the cache first \n",
    "            session_items_test = self.items_for_session( session )\n",
    "            \n",
    "            similarity = getattr(self , self.similarity)(session_items_test, session_items)\n",
    "            if similarity > 0:\n",
    "                neighbors.append((session, similarity))\n",
    "                \n",
    "        return neighbors\n",
    "    \n",
    "    def find_neighbors( self, session_items, input_item_id, session_id):\n",
    "        possible_neighbors = self.possible_neighbor_sessions( session_items, input_item_id, session_id )\n",
    "        possible_neighbors = self.calc_similarity( session_items, possible_neighbors )\n",
    "        \n",
    "        possible_neighbors = sorted( possible_neighbors, reverse=True, key=lambda x: x[1] )\n",
    "        possible_neighbors = possible_neighbors[:self.k]\n",
    "        \n",
    "        return possible_neighbors\n",
    "    \n",
    "    def score_items(self, neighbors):\n",
    "        scores = dict()\n",
    "        # iterate over the sessions\n",
    "        for session in neighbors:\n",
    "            # get the items in this session\n",
    "            items = self.items_for_session( session[0] )\n",
    "            \n",
    "            for item in items:\n",
    "                old_score = scores.get( item )\n",
    "                new_score = session[1]\n",
    "                \n",
    "                if old_score is None:\n",
    "                    scores.update({item : new_score})\n",
    "                else: \n",
    "                    new_score = old_score + new_score\n",
    "                    scores.update({item : new_score})\n",
    "                    \n",
    "        return scores\n",
    "    \n",
    "    def results(self, session_id, input_item_id, predict_for_item_ids):\n",
    "        score = self.predict_next(session_id, input_item_id, predict_for_item_ids)\n",
    "        score_frame = score.to_frame() \n",
    "        score_frame.reset_index(inplace=True)\n",
    "        score_frame.columns = ['item_id','score']\n",
    "        sort_by_score = score_frame.sort_values('score',ascending=False)\n",
    "        sknn_results=[]\n",
    "        for i in sort_by_score.head(10).item_id:\n",
    "            sknn_results.append(i)\n",
    "        return sknn_results\n",
    "            \n",
    "    def clear(self):\n",
    "        self.session = -1\n",
    "        self.session_items = []\n",
    "        self.relevant_sessions = set()\n",
    "\n",
    "        self.session_item_map = dict() \n",
    "        self.item_session_map = dict()\n",
    "        self.session_time = dict()\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[174, 224, 226, 196, 225, 134, 127, 285, 43, 279]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sknn = SKNN()\n",
    "sknn.train_data(data)\n",
    "ids = data.ItemId.unique()\n",
    "sknn.results(session_id = 7,\n",
    "                 input_item_id = 224,\n",
    "                 predict_for_item_ids = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/topics/song-recommender\n",
    "# https://github.com/caravanuden/spotify_recsys\n",
    "# https://github.com/topics/music-recommendation\n",
    "# https://github.com/kartikjagdale/Last.fm-Song-Recommender\n",
    "# https://github.com/mrthlinh/Spotify-Playlist-Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMF (Session based MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SessionMF:\n",
    "#     def __init__( self, factors=100, batch=50, learn='adagrad_sub', learning_rate=0.001, momentum=0.0, regularization=0.5, \n",
    "#                  dropout=0.0, skip=0, samples=2048, activation='linear', objective='bpr_max_org', epochs=10, last_n_days=None, \n",
    "#                  session_key = 'SessionId', item_key= 'ItemId', time_key= 'Time' ):\n",
    "       \n",
    "#         self.factors = factors\n",
    "#         self.batch = batch\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.momentum = momentum\n",
    "#         self.learn = learn\n",
    "#         self.regularization = regularization\n",
    "#         self.samples = samples\n",
    "#         self.dropout = dropout\n",
    "#         self.skip = skip\n",
    "#         self.epochs = epochs\n",
    "#         self.activation = activation\n",
    "#         self.objective = objective\n",
    "#         self.last_n_days = last_n_days\n",
    "#         self.session_key = session_key\n",
    "#         self.item_key = item_key\n",
    "#         self.time_key = time_key\n",
    "        \n",
    "#         #updated while recommending\n",
    "#         self.session = -1\n",
    "#         self.session_items = []\n",
    "#         self.relevant_sessions = set()\n",
    "\n",
    "#         # cache relations once at startup\n",
    "#         self.session_item_map = dict() \n",
    "#         self.item_session_map = dict()\n",
    "#         self.session_time = dict()\n",
    "        \n",
    "#         self.item_map = dict()\n",
    "#         self.item_count = 0\n",
    "#         self.session_map = dict()\n",
    "#         self.session_count = 0\n",
    "        \n",
    "#         self.floatX = theano.config.floatX\n",
    "#         self.intX = 'int32'\n",
    "    \n",
    "#     def fit(self, data, items=None):\n",
    "#         self.unique_items = data[self.item_key].unique().astype( self.intX )\n",
    "#         self.num_items = data[self.item_key].nunique()\n",
    "#         self.item_list = np.zeros( self.num_items )\n",
    "        \n",
    "#         start = time.time()\n",
    "#         self.init_items(data)\n",
    "#         print( 'finished init item map in {}'.format(  ( time.time() - start ) ) )\n",
    "        \n",
    "#         if self.last_n_days != None:\n",
    "            \n",
    "#             max_time = dt.fromtimestamp( data[self.time_key].max() )\n",
    "#             date_threshold = max_time.date() - td( self.last_n_days )\n",
    "#             stamp = dt.combine(date_threshold, dt.min.time()).timestamp()\n",
    "#             train = data[ data[self.time_key] >= stamp ]\n",
    "        \n",
    "#         else: \n",
    "#             train = data\n",
    "        \n",
    "#         self.init_sessions( train )\n",
    "            \n",
    "#         start = time.time()\n",
    "#         self.init_model( train )\n",
    "#         print( 'finished init model in {}'.format(  ( time.time() - start ) ) )\n",
    "        \n",
    "#         start = time.time()\n",
    "        \n",
    "#         avg_time = 0\n",
    "#         avg_count = 0\n",
    "                   \n",
    "#         for j in range( self.epochs ):\n",
    "            \n",
    "#             loss = 0\n",
    "#             count = 0\n",
    "#             hit = 0\n",
    "            \n",
    "#             batch_size = set(range(self.batch))\n",
    "                    \n",
    "#             ipos = np.zeros( self.batch ).astype( self.intX )\n",
    "#             #ineg = np.zeros( self.batch ).astype( self.intX )\n",
    "            \n",
    "#             finished = False\n",
    "#             next_sidx = len(batch_size)\n",
    "#             sidx = np.arange(self.batch)\n",
    "#             spos = np.ones( self.batch ).astype( self.intX )\n",
    "#             svec = np.zeros( (self.batch, self.num_items) ).astype( self.floatX )\n",
    "#             smat = np.zeros( (self.batch, self.num_items) ).astype( self.floatX )\n",
    "#             sci = np.zeros( self.batch ).astype( self.intX )\n",
    "#             scp = np.zeros( self.batch ).astype( self.intX )\n",
    "                        \n",
    "#             while not finished:\n",
    "                \n",
    "#                 #rand = []\n",
    "#                 ran = np.random.random_sample()\n",
    "#                 items = set()\n",
    "#                 itemsl = None\n",
    "                \n",
    "#                 for i in range(self.batch):\n",
    "                    \n",
    "#                     item_pos = self.session_map[ self.sessions[ sidx[i] ] ][ spos[i] ]\n",
    "#                     if ran < self.skip and len(self.session_map[ self.sessions[ sidx[i] ] ]) > spos[i] + 1:\n",
    "#                         item_pos = self.session_map[ self.sessions[ sidx[i] ] ][ spos[i] + 1 ]\n",
    "                        \n",
    "#                     item_current = self.session_map[ self.sessions[ sidx[i] ] ][ spos[i] - 1 ]\n",
    "#                     #prev = spos[i] - 1 if spos[i] - 1 > 0 else spos[i]\n",
    "#                     #item_prev = self.session_map[ self.sessions[ sidx[i] ] ][ prev ]\n",
    "#                     items.update(self.session_map[ self.sessions[ sidx[i] ] ][ :spos[i] ])\n",
    "#                     #items.extend(self.session_map[ self.sessions[ sidx[i] ] ][ :spos[i] - 1 ])\n",
    "                    \n",
    "#                     ipos[i] = item_pos\n",
    "#                     sci[i] = item_current\n",
    "#                     #scp[i] = item_current\n",
    "#                     svec[i][ sci[i] ] = spos[i]\n",
    "#                     smat[i] = svec[i] / spos[i]\n",
    "#                     if self.dropout > 0:\n",
    "#                         itemsl = list(items)\n",
    "#                         smat[i][itemsl] = smat[i][itemsl] * np.random.choice(2,size=len(itemsl),p=[self.dropout,1-self.dropout])\n",
    "                        \n",
    "#                     spos[i] += 1\n",
    "                \n",
    "                \n",
    "#                 if self.samples > 0:\n",
    "#                     #additional = samples\n",
    "#                     additional = np.random.randint(self.num_items, size=self.samples).astype( self.intX )\n",
    "#                     stmp = time.time()\n",
    "#                     if itemsl is None:\n",
    "#                         itemsl = list(items)\n",
    "#                     loss += self.train_model_batch( smat, sci, np.hstack( [ipos, additional] ), itemsl )\n",
    "#                     avg_time += (time.time() - stmp)\n",
    "#                     avg_count += 1\n",
    "#                 else:\n",
    "#                     loss +=  self.train_model_batch( smat, sci, ipos, scp )\n",
    "                \n",
    "\n",
    "#                 if np.isnan(loss):\n",
    "#                     print(str(j) + ': NaN error!')\n",
    "#                     self.error_during_train = True\n",
    "#                     return\n",
    "                \n",
    "#                 count += self.batch\n",
    "                          \n",
    "#                 for i in range(self.batch):\n",
    "#                     if len( self.session_map[ self.sessions[ sidx[i] ] ] ) == spos[i]: #session end\n",
    "#                         if next_sidx < len( self.sessions ):\n",
    "#                             spos[i] = 1\n",
    "#                             sidx[i] = next_sidx\n",
    "#                             svec[i] = np.zeros( self.num_items ).astype( self.floatX )\n",
    "#                             next_sidx += 1\n",
    "#                         else:\n",
    "#                             spos[i] -= 1\n",
    "#                             batch_size -= set([i])\n",
    "                    \n",
    "#                     if len(batch_size) == 0:\n",
    "#                         finished = True\n",
    "                            \n",
    "#             print( 'finished epoch {} with loss {} / hr {} in {}s'.format( j, ( loss / count ), ( hit / count ), ( time.time() - start ) ) )\n",
    "            \n",
    "#         print( 'avg_time_fact: ',( avg_time / avg_count ) )\n",
    "    \n",
    "#     def init_model(self, train, std=0.01):\n",
    "        \n",
    "#         self.I = theano.shared( np.random.normal(0, std, size=(self.num_items, self.factors) ).astype( self.floatX ), name='I' )\n",
    "#         self.S = theano.shared( np.random.normal(0, std, size=(self.num_items, self.factors) ).astype( self.floatX ), name='S' )\n",
    "        \n",
    "#         self.I1 = theano.shared( np.random.normal(0, std, size=(self.num_items, self.factors) ).astype( self.floatX ), name='I1' )\n",
    "#         self.I2 = theano.shared( np.random.normal(0, std, size=(self.num_items, self.factors) ).astype( self.floatX ), name='I2' )\n",
    "\n",
    "#         self.BS = theano.shared( np.random.normal(0, std, size=(self.num_items,1) ).astype( self.floatX ), name='BS' )\n",
    "#         self.BI = theano.shared( np.random.normal(0, std, size=(self.num_items,1) ).astype( self.floatX ), name='BI' )\n",
    "        \n",
    "#         self.hack_matrix = np.ones((self.batch, self.batch + self.samples), dtype=self.floatX)\n",
    "#         np.fill_diagonal(self.hack_matrix, 0)\n",
    "#         self.hack_matrix = theano.shared(self.hack_matrix, borrow=True)\n",
    "        \n",
    "#         self._generate_train_model_batch_function()\n",
    "#         self._generate_predict_function()\n",
    "#         self._generate_predict_batch_function()\n",
    "    \n",
    "#     def init_items(self, train):\n",
    "        \n",
    "#         index_item = train.columns.get_loc( self.item_key )\n",
    "                \n",
    "#         for row in train.itertuples(index=False):\n",
    "            \n",
    "#             ci = row[index_item]\n",
    "            \n",
    "#             if not ci in self.item_map: \n",
    "#                 self.item_map[ci] = self.item_count\n",
    "#                 self.item_list[self.item_count] = ci\n",
    "#                 self.item_count = self.item_count + 1                  \n",
    "    \n",
    "#     def init_sessions(self, train):\n",
    "        \n",
    "#         index_session = train.columns.get_loc( self.session_key )\n",
    "#         index_item = train.columns.get_loc( self.item_key )\n",
    "        \n",
    "#         self.sessions = []\n",
    "#         self.session_map = {}\n",
    "        \n",
    "#         train.sort_values( [self.session_key,self.time_key], inplace=True )\n",
    "        \n",
    "#         prev_session = -1\n",
    "        \n",
    "#         for row in train.itertuples(index=False):\n",
    "            \n",
    "#             item = self.item_map[ row[index_item] ]\n",
    "#             session = row[index_session]\n",
    "            \n",
    "#             if prev_session != session: \n",
    "#                 self.sessions.append(session)\n",
    "#                 self.session_map[session] = []\n",
    "            \n",
    "#             self.session_map[session].append(item)\n",
    "#             prev_session = session\n",
    "    \n",
    "#     def _generate_train_model_batch_function(self):\n",
    "        \n",
    "#         s = T.matrix('s', dtype=self.floatX)\n",
    "#         i = T.vector('i', dtype=self.intX)\n",
    "#         y = T.vector('y', dtype=self.intX)\n",
    "#         items = T.vector('items', dtype=self.intX)\n",
    "        \n",
    "#         Sit = self.S[items]\n",
    "#         sit = s.T[items]\n",
    "        \n",
    "#         Iy = self.I[y]\n",
    "#         BSy = self.BS[y]\n",
    "#         BIy = self.BI[y]\n",
    "        \n",
    "#         I1i = self.I1[i]\n",
    "#         I2y = self.I2[y]\n",
    "        \n",
    "#         se = T.dot( Sit.T, sit )\n",
    "#         predS =  T.dot( Iy, se ).T + BSy.flatten()\n",
    "        \n",
    "#         predI = T.dot( I1i, I2y.T ) + BIy.flatten()\n",
    "        \n",
    "#         pred = predS + predI\n",
    "#         pred = getattr(self, self.activation )( pred )\n",
    "        \n",
    "#         cost = getattr(self, self.objective )( pred, y )\n",
    "        \n",
    "#         #updates = getattr(self, self.learn)(cost, [self.S,self.I,self.IC,self.BI,self.BS], self.learning_rate)\n",
    "#         updates = getattr(self, self.learn)(cost, [self.S,self.I,self.I1,self.I2,self.BI,self.BS], [Sit,Iy,I1i,I2y,BIy,BSy],[items,y,i,y,y,y], self.learning_rate, momentum=self.momentum)\n",
    "        \n",
    "#         self.train_model_batch = theano.function(inputs=[s, i, y, items], outputs=cost, updates=updates  )\n",
    "    \n",
    "#     def _generate_predict_function(self):\n",
    "        \n",
    "#         s = T.vector('s', dtype=self.floatX)\n",
    "#         i = T.scalar('i', dtype=self.intX)\n",
    "        \n",
    "#         se = T.dot( self.S.T, s.T )\n",
    "        \n",
    "#         predS = T.dot( self.I, se ).T + self.BS.flatten()\n",
    "#         predI = T.dot( self.I1[i], self.I2.T ) + self.BI.flatten()\n",
    "        \n",
    "#         pred = predS + predI\n",
    "#         pred = getattr(self, self.activation )( pred )\n",
    "        \n",
    "#         self.predict = theano.function(inputs=[s, i], outputs=pred )\n",
    "    \n",
    "#     def _generate_predict_batch_function(self):\n",
    "        \n",
    "#         s = T.matrix('s', dtype=self.floatX)\n",
    "#         i = T.vector('i', dtype=self.intX)\n",
    "        \n",
    "#         se = T.dot( self.S.T, s.T )\n",
    "        \n",
    "#         predS = T.dot( self.I, se ).T + self.BS\n",
    "#         predI = T.dot( self.I1[i], self.I2.T ) + self.BI\n",
    "        \n",
    "#         pred = predS + predI\n",
    "        \n",
    "#         pred = getattr(self, self.activation )( pred )\n",
    "        \n",
    "#         self.predict_batch = theano.function(inputs=[s, i], outputs=pred ) #, updates=updates )\n",
    "        \n",
    "#     def bpr_max_org(self, pred_mat, y):\n",
    "#         softmax_scores = self.softmax_neg(pred_mat).T\n",
    "#         return T.cast(T.mean(-T.log(T.sum(T.nnet.sigmoid(T.diag(pred_mat)-pred_mat.T)*softmax_scores, axis=0)+1e-24)+self.regularization*T.sum((pred_mat.T**2)*softmax_scores, axis=0)), self.floatX)\n",
    "    \n",
    "    \n",
    "#     def softmax_neg(self, X):\n",
    "#         if hasattr(self, 'hack_matrix'):\n",
    "#             X = X * self.hack_matrix\n",
    "#             e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x')) * self.hack_matrix\n",
    "#         else:\n",
    "#             e_x = T.fill_diagonal(T.exp(X - X.max(axis=1).dimshuffle(0, 'x')), 0)\n",
    "#         return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "    \n",
    "#     def adagrad_sub(self, loss, param_list, subparam_list, idx, learning_rate=1.0, epsilon=1e-6, momentum=0.0 ):\n",
    "        \n",
    "#         updates = []\n",
    "\n",
    "#         all_grads = theano.grad(loss, subparam_list)\n",
    "        \n",
    "#         for i in range(len(all_grads)):\n",
    "            \n",
    "#             grad = all_grads[i]\n",
    "#             param = param_list[i]\n",
    "#             index = idx[i]\n",
    "#             subparam = subparam_list[i]\n",
    "            \n",
    "#             accu = theano.shared(param.get_value(borrow=False) * 0., borrow=True)\n",
    " \n",
    "#             accu_s = accu[index]\n",
    "#             accu_new = accu_s + grad ** 2\n",
    "#             updates.append( ( accu, T.set_subtensor(accu_s, accu_new) ) )\n",
    "            \n",
    "#             delta = learning_rate * grad / T.sqrt(accu_new + epsilon)\n",
    "            \n",
    "#             if momentum > 0:\n",
    "#                 velocity = theano.shared(param.get_value(borrow=False) * 0., borrow=True)\n",
    "#                 vs = velocity[index]\n",
    "#                 velocity2 = momentum * vs - delta\n",
    "#                 updates.append( ( velocity, T.set_subtensor(vs, velocity2) ) )\n",
    "#                 updates.append( ( param, T.inc_subtensor(subparam, velocity2 ) ) )\n",
    "#             else:\n",
    "#                 updates.append( ( param, T.inc_subtensor(subparam, - delta ) ) )\n",
    "            \n",
    "#         return updates\n",
    "    \n",
    "#     def linear(self, param):\n",
    "#         return param\n",
    "    \n",
    "#     def sigmoid(self, param):\n",
    "#         return T.nnet.sigmoid( param )\n",
    "    \n",
    "#     def predict_next( self, session_id, input_item_id, predict_for_item_ids, input_user_id=None, skip=False, type='view', timestamp=0 ):\n",
    "#         if( self.session != session_id ): #new session      \n",
    "                \n",
    "#             self.session = session_id\n",
    "#             self.session_items = np.zeros(self.num_items, dtype=np.float32)\n",
    "#             self.session_count = 0\n",
    "        \n",
    "#         if type == 'view':\n",
    "#             self.session_count += 1\n",
    "#             self.session_items[ self.item_map[input_item_id] ] = self.session_count\n",
    "        \n",
    "#         if skip:\n",
    "#             return\n",
    "         \n",
    "#         predictions = self.predict( self.session_items / self.session_count, self.item_map[input_item_id] )\n",
    "#         series = pd.Series(data=predictions, index=self.item_list)\n",
    "#         series = series[predict_for_item_ids]\n",
    "                \n",
    "#         return series\n",
    "    \n",
    "#     def clear(self):\n",
    "#         self.I.set_value([[]])\n",
    "#         self.S.set_value([[]])\n",
    "#         self.I1.set_value([[]])\n",
    "#         self.I2.set_value([[]])\n",
    "#         self.BS.set_value([[]])\n",
    "#         self.BI.set_value([[]])\n",
    "#         self.hack_matrix.set_value([[]])\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished init item map in 0.001996755599975586\n",
      "finished init model in 1.1431427001953125\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-9ca6877d911a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSessionMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-68ca9fe6bd13>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, items)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                     \u001b[0mitem_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_map\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0msidx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mspos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mran\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_map\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0msidx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mspos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                         \u001b[0mitem_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_map\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0msidx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mspos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "smf = SessionMF()\n",
    "smf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
